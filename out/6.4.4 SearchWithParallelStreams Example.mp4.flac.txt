So now you've had a chance to look at the parallel stream implementation, evaluate the pros and cons of this approach.
 And, of course, we're going to evaluate it in a couple ways when evaluated, in terms of comparing it to search for sequential streams, version in the law. Also evaluated, in terms of other approaches that may be even more scalable.
 Let's take a look at the pros, first. I think, clearly this example demonstrates the minuscule differences between sequential and parallel streams.
 Here's what it looked like with the surface sequential stream implementation. We saw earlier.
 And here's what it looks like with search with parallel streams. And as you can see, there's just one tiny minuscule difference and that's often the way things are so cool. You really have to step back and tip your hat and admire the genius of the people who came up with this framework because it's so powerful. So, convenient and scale, so nicely with, so little work on the part of a programmer. So I really am endlessly impressed with how clever the designers of java streams were to come up with this model. That was so easy to optimize and that's really the heart. Of course of parallel functional programming being able to keep a functional programming veneer of, of design and implementation and then magically paralyzed stuff. With very little work on your part. All the details are pushed into the infrastructure, which is the whole point of declarative programming in the first place.
 Even though we made very simple changes. We ended up with substantial speedups on the multi-core processor. If you take a close, look at this little screen and I show here, you can see that the best performance of the sequential streams model was roughly. I think about two thousand milliseconds on my quad core laptop, with lots of memory and the performance of The Parallel streams version with that little minuscule, change was about five times faster, four to five times faster. So is quite a big speed up and this is with a 2.7 gigahertz quad-core.
 Do a machine running Windows. I also have a MacBook Pro, which is a 2.9 gigahertz quad-core machine, which doesn't have as much memory, but the processes are faster. And if you look at the performance results, you'll see a similar Trend in terms of speed up, but you'll see that the performance is actually higher because it's a faster processor. So the key Point here is just, you know, your mileage may vary as a don't be surprised if that you run this on your machine and you get slightly different results, but I would expect if you've got multiple cores, that the parallel version will run considerably faster. And because it's inherently and embarrassingly parallel program searching for these different strains in in the works of Shakespeare searching for the phrases of the works of Shakespeare is embarrassing parallel. You would expect to see this type of Skillet. I should also point out to the searching for strings in the work of Shakespeare.
 Is a compute bound processes to compute Brown problem. And so there's really no Ayo happening here. We're just searching in memory to look for those those phrases of strength.
 The reason why we get there kind of super linear speed up, arises from the use of hyper threading in modern, multi-core processors. So these are what are also from school virtual cores. And the basic idea is that the piper threaded model increases the number of independent instructions that can run in parallel, by using what's known as a super Skinner architecture. And what does basically does is it allows more than one instruction to execute per clock cycle by simultaneously dispatching, multiple instructions to different execution units. So, if you take a look at that picture that's here, which you can read about at the Wikipedia link at the bottom of the slide. It's basically able to run the various operations in pipelines, where they end up running in parallel. Now, you don't typically get as much of a parallel boost as you do by having a physical core, but in the right circumstances things to do, in fact, run faster as we can see here.
 Well, as always, things are never entirely unicorns and rainbows as I like to say, so just because two miniscule, changes were needed to go from sequential street names to Carol Streams, doesn't mean it's the best way to go. So it turns out that there's other job of Frameworks, other concurrency, and parallelism Frameworks and strategies that are even more efficient than those simple changes. We made with a parallel streams of limitation. Now, before I bash the parallel streams version too much. Let's just know the couple things. First live performance, radically better with these other approaches if they're better, but they're not radically better.
 The other approaches took more work to implement and being able to get basically at Super linear speed up might be sufficient to meet your requirements. So it's not always necessary to rain in every last nanosecond of performance out of your software. You may just need to get it to the point where it meets the requirements of the customer of the user's. So this discussion really is not to throw shade on Parallel streams. It's to say that there's more advanced ways which we will cover, of course of making things, right? Even faster if you're willing to put a bit more work into it.
 Now, naturally, your mileage may vary and different factors like the amount of memory that you've got, and the version of the, the Java. Jdk you have will make a difference job. You were job aversions almost invariably add performance enhancements. They fix bugs. They optimize things, they make things run in parallel better. They removed internal locks and so on and so forth. So there's no substitute for systematic, benchmarking and experimentation. So just be aware of the fact that that's always important when you when you write parallel code.
 We will see in an upcoming lesson in the upcoming week. There is yet another, even more efficient way of doing this, which we have named search with parallel, split a writer. And as a name implies. This uses, the Perils of the techniques. We talked about so far plus adding the concept of parallel splitter Riders. And so, this turns out to be the, most aggressive pros, and strategy that we Implement. And as a consequence, it ends up being much finer-grained. And able to take you to more advantage of multiple course. And as you might expect, the more cores, you have the bigger when you will get from using even more perilous. That's another kind of tip to kind of keep in the back of your mind.