00:00.700 --> 00:08.500
We're not going to turn our attention to one of the processing phases and discuss the order of processing and we'll see

00:08.500 --> 00:09.000
Once again

00:09.000 --> 00:12.900
it's important to know what you can change and what you can't change

00:14.300 --> 00:17.400
So let's talk about stream processing order

00:17.400 --> 00:18.500
What the heck does that mean

00:18.500 --> 00:19.400
Well

00:19.400 --> 00:29.400
keep in mind when we talk about processing order were in the apply face and this is the phase where the chunks that were created by the split phase

00:29.400 --> 00:35.500
Are they a map to the underlying common for drain pool to be running parallel

00:35.500 --> 00:36.700
Now

00:36.700 --> 00:40.600
it turns out that the order in which the chunks in a parallel streamer

00:40.600 --> 00:43.900
processed is intentionally non-deterministic

00:43.900 --> 00:50.000
What that means is is you have no control over it and will happen here

00:50.000 --> 00:52.300
is that the way in which the fork join pool

00:52.300 --> 00:55.900
takes the tasks that it's been given and runs them

00:55.900 --> 00:59.500
Can be different for different Ron's

00:59.500 --> 01:01.600
be different on different Hardware different

01:01.600 --> 01:03.100
A different operating systems different

01:03.100 --> 01:05.400
different versions of the job of execution

01:05.400 --> 01:05.900
environment

01:05.900 --> 01:07.100
Java virtual machine is still on

01:07.100 --> 01:08.700
even for the same input

01:09.400 --> 01:13.600
And programmers have little or no control over that

01:13.600 --> 01:16.000
You just can't do anything about it

01:16.000 --> 01:18.400
And that's actually by Design

01:18.400 --> 01:19.800
The reason for doing this

01:19.800 --> 01:29.200
is it enables the various layers in the job execution environment JDM Java virtual machine or something

01:29.200 --> 01:32.800
Like the Android Arch runtime environment

01:32.800 --> 01:35.500
which uses ahead of time compilation is supposed to work

01:35.500 --> 01:37.400
The machine and interpretation

01:37.400 --> 01:42.500
All of these kinds of things can be optimized in ways that are transparent to your coat

01:42.500 --> 01:47.900
So the way in which tasks are scheduled and executed in the fork

01:47.900 --> 01:50.700
join pool on the execution environment that they

01:50.700 --> 01:51.200
the end

01:51.200 --> 01:54.000
the hard work or is the operating system after system thread

01:54.000 --> 01:58.500
all of those things to be optimized in a way that's totally transparent to you

01:58.500 --> 01:59.700
And that's a good thing

01:59.700 --> 02:02.300
You don't really want to have to know about those details

02:03.800 --> 02:04.700
Good example

02:04.700 --> 02:07.100
of where Salon determines that might come from

02:07.100 --> 02:10.100
is the fork join framework

02:10.100 --> 02:15.200
Support for work stealing to talk a lot about work stealing when we talked about before

02:15.200 --> 02:16.100
Join framework

02:16.100 --> 02:21.900
We'll talk a little bit about it when we talk about how the parallel streams framework uses for join pool

02:21.900 --> 02:27.300
but they see what happens is if you've got the workers Fred's in the fourth join

02:27.300 --> 02:36.800
Have their own internal to which is called a deck for a double-ended cute and whenever a worker thread has no work on its deck

02:36.800 --> 02:48.700
it turns around and tries to steal available work from other workers threads decks in order to be able to have the performance maximized of the CPU of the multi-core processors

02:48.700 --> 02:53.500
And the reason for doing this is to improve overall

02:53.500 --> 02:54.300
through put in the system

02:54.300 --> 02:57.900
but it also leads to a lot of non determinism and that's perfectly

02:57.900 --> 02:58.000
Okay

02:58.000 --> 02:59.000
That's what you want