We're going to do now is start taking a look at the various phases in a Java parallel streams and peek under the hood and this of course, is important to give you a bigger and better understanding with actually taking place behind the scenes when you run your pedals dreams programs.
 A job apparel stream. Implements a variant of the famous mapreduce model, which is optimized for multi-core processors. If you're familiar with mapreduce from other context, you probably know it's used for things like cluster basic Computing. What do you end up being able to map your tasks your jobs to multiple computers in a cluster and then be able to get the results back and reduce them to a final result. A good example of this would be something like Google's search engine which uses many computers to do, the searching efficiently and Impala. It turns out that job at parallel streams. Works a little differently. I'll do the basic concept is very similar in particular, the mapreduce model for Java. Carol Streams works on a multi-core processor rather than a cluster. If you want to use cluster stop programming, you have to work with a different type of programming Middle where things like, perhaps Hadoop or Sparks naturally the topics
 Over here for Palace dreams, could also work in that context as well. This diagram gives a somewhat Whimsical but fairly realistic rendition of the mapreduce process. So imagine we want to make a sandwich and we've got a bunch of various components. In our refrigerator. We have bread and lettuce and meat, and cheese and tomatoes. So the first phase of this is basically to partition the elements in our fridge and put them out on the table. And then we're going to do is do the map phase where props in parallel different people could slice up the bread, Shred the lettuce slice, the meat spicy cheese, slice, the tomatoes, and so on. And then a different group of people could take those various slices and shredded lettuce and then reduce them by putting together sandwiches. And if you play your cards, right, you could end up having a nice little pipeline of parallel processing, in order to be able to make your sandwiches more quickly and more effectively.
 Obviously, we're not dealing with making sandwiches here. Would you lie was ready? Ready for Peter programs that wants to take good advantage of multi-core processors. So what actually happens, of course in a parallel stream is this split apply and combine data processing strategy that we've talked about multiple times earlier and now we're really going to get a chance to talk about the parallel aspects of that.
 So if you recall the three phases in the split, apply combine Paradigm are first split which will end up recursively partitioning a data source up into chunks. And even think of this kind of like they're slicing up pieces of pizza as we showed her the picture.
 We'll be talking about this in more detail in an upcoming lesson. But for right now, is part of the overview basically went out with a bunch of chunks that is independent, and essentially, an atomic subset of a portion or partition of the original data source, and this partition in may take place recursively in multiple steps in order to be able to get the original data into smaller pieces to be processed effectively in parallel.
 The way this is. Of course, in Java and JavaScript teams is through split. Raiders, the split Raiders. They used to partition data sources in particular collections in Java.
 The try Advance method which we talked about in previous weeks is used for both sequential and parallel streams. And of course, the other important methods which is called Tri split is only used for palestrina's, and we'll talk a lot about that as we go further in these lessons in this week in subsequent weeks.
 Each job Collection comes with a predefined split writer, as I've mentioned, before this split erator, implementation is provided as a default method in the Java collection interface. And you can see how split writer has a default implementation there, which of course, can be overridden by various containers and elections that will Implement collection either directly or indirectly. And you could also see how the Pearl stream method uses splitter Ator.
 So if you take a look here, you can see how the travel screen method uses a splitter ater along with the stream support. Stream method to create a parallel stream. And you can see it's a perilous train because the trooper amateur is passed into stream support. Stream.
 It's also possible to Define your own custom Splitters. We've shown some examples of this before in the context of our phrase, Matt's literator from the sequential search screen, get an application. And also with the splitter that we used earlier for the simple search stream, example, we're going to be looking at other aspects of Customs split Raiders here. In the parallel string section is
 Not surprisingly, parallel streams will perform best. If your data sources can be split efficiently and can be split evenly and I'll have a whole discussion of that later and I'll show you some results from performance analysis. That quantifies, the differences between different Java Collections in terms of how evenly and how efficiently they split up their data.
 The second phase in this process is the apply phase. And unlike the earlier discussions. We had for sequential streams were there was only one Fred think that a lot more interesting. We start dealing, with parallel streams in this context. The process chunks. The chunks that are created by the split. Aerator are processed in parallel, in the common, for joints Red Bull, and it has to be the coming-forth joint for. That's the way that streams are designed to work.
 It turns out that the splitting and applying phases actually, run simultaneously after certain limit their men, after you've created enough chunks, as part of splitting, those get fed into the 4th drawing for and then they start to run in parallel. This is not a purely sequential thing. But the splitting doesn't take place first followed by all the applying instead. They're there interleague. Thereby allowing the program to start running were quickly and get results were quickly.
 The way that this works under the hood is we'll talk about in much more detail. Later is by using something called work stealing, and this is designed intentionally to maximize CPU processor core utilization. The goal is to keep things as busy as possible, and never let the threads of the process, of course, block or sleep for any length of time. Is that tested? Great performance quite a bit on Modern multi-core processors.
 Programmers, get some degree of control of the number of threads in the common Fork. Join pool will will talk extensively about how to do this. Both here in the parallel streams discussion, as well as also later when we cover the job of work joint for framework itself. So you'll get a number of different perspectives on how to control the number of threads in the pool.
 The third and final phase is the combined phase which works by joining the partial results with your credit in the different threads running in the pool. As part of the apply phase into a single so-called reduced result has been a lot of time talking about this as well.
 This is typically done by terminal operations, like collect and reduce.
 And as we'll see that the collectors that are used by collect can be either concurrent, which means that they have to be synchronized. They have to use accumulators that synchronized access to a single shared, beautiful result container or they can collections don't. The collectors don't have to be synchronized. Of course, we'll also talked extensively about that as well.