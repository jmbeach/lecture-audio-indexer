WEBVTT

1
00:00:00.000 --> 00:00:00.750 align:middle line:90%


2
00:00:00.750 --> 00:00:04.140 align:middle line:84%
Now that we've talked about
how to visualize the hook

3
00:00:04.140 --> 00:00:07.290 align:middle line:84%
methods for the
SearchWithParallelStreams case

4
00:00:07.290 --> 00:00:09.390 align:middle line:84%
study example, let's
go ahead and take

5
00:00:09.390 --> 00:00:13.120 align:middle line:84%
a look at how to implement
these hook methods.

6
00:00:13.120 --> 00:00:14.967 align:middle line:84%
And again, just to
remind you, the reason

7
00:00:14.967 --> 00:00:16.800 align:middle line:84%
for doing what we're
doing here-- the reason

8
00:00:16.800 --> 00:00:20.060 align:middle line:84%
for using parallel streams--
is to get this massive speed-up

9
00:00:20.060 --> 00:00:22.770 align:middle line:84%
in performance, which, if
you take a look at this,

10
00:00:22.770 --> 00:00:26.220 align:middle line:84%
is basically about
linear or super linear

11
00:00:26.220 --> 00:00:29.730 align:middle line:84%
in the number of
cores on the laptop I

12
00:00:29.730 --> 00:00:31.470 align:middle line:90%
ran the experiments on.

13
00:00:31.470 --> 00:00:33.750 align:middle line:84%
The reason why the results
are actually super linear--

14
00:00:33.750 --> 00:00:35.280 align:middle line:84%
in other words,
better than linear--

15
00:00:35.280 --> 00:00:38.550 align:middle line:84%
is because even though
I have fours cores,

16
00:00:38.550 --> 00:00:41.160 align:middle line:84%
they're hyperthreaded,
which means

17
00:00:41.160 --> 00:00:43.590 align:middle line:84%
they're able to do some
overlapping of instructions

18
00:00:43.590 --> 00:00:46.620 align:middle line:84%
and pipelining in order to get
the performance even higher

19
00:00:46.620 --> 00:00:48.450 align:middle line:90%
than just a factor of n.

20
00:00:48.450 --> 00:00:53.008 align:middle line:84%
It's really not quite double
n, but it's more than n--

21
00:00:53.008 --> 00:00:54.300 align:middle line:90%
where n is the number of cores.

22
00:00:54.300 --> 00:00:56.628 align:middle line:84%
So this really does
give you a big win,

23
00:00:56.628 --> 00:00:58.170 align:middle line:84%
and we'll talk more
about the reasons

24
00:00:58.170 --> 00:01:00.990 align:middle line:90%
why that is a little bit later.

25
00:01:00.990 --> 00:01:04.610 align:middle line:84%
So let's talk about how we might
implement the processStream

26
00:01:04.610 --> 00:01:05.660 align:middle line:90%
method.

27
00:01:05.660 --> 00:01:08.180 align:middle line:84%
Now, the key thing to note
before we talk about anything

28
00:01:08.180 --> 00:01:11.240 align:middle line:84%
here is there's only
one minuscule change

29
00:01:11.240 --> 00:01:16.300 align:middle line:84%
to processStream in
this implementation.

30
00:01:16.300 --> 00:01:19.840 align:middle line:84%
All we're doing is
replacing the use of stream

31
00:01:19.840 --> 00:01:22.030 align:middle line:90%
with parallelStream.

32
00:01:22.030 --> 00:01:24.130 align:middle line:84%
And what that does
under the hood

33
00:01:24.130 --> 00:01:27.600 align:middle line:84%
is that goes ahead and uses
the array list spliterator

34
00:01:27.600 --> 00:01:31.610 align:middle line:84%
rater to create a
parallel stream that

35
00:01:31.610 --> 00:01:34.850 align:middle line:84%
will search the array
list of input strings

36
00:01:34.850 --> 00:01:37.540 align:middle line:90%
in multiple worker threads.

37
00:01:37.540 --> 00:01:40.940 align:middle line:84%
So basically, each-- as the way
that the array list spliterator

38
00:01:40.940 --> 00:01:41.440 align:middle line:90%
works.

39
00:01:41.440 --> 00:01:43.510 align:middle line:84%
As we'll look at
shortly, I'll actually

40
00:01:43.510 --> 00:01:47.350 align:middle line:84%
walk through the source code
for the array list spliterator

41
00:01:47.350 --> 00:01:48.845 align:middle line:84%
to show you exactly
how it works.

42
00:01:48.845 --> 00:01:50.470 align:middle line:84%
But basically, what
it ends up doing is

43
00:01:50.470 --> 00:01:52.900 align:middle line:84%
it ends up splitting
the array list up

44
00:01:52.900 --> 00:01:57.730 align:middle line:84%
into chunks, where each chunk
is a single element in the array

45
00:01:57.730 --> 00:01:58.870 align:middle line:90%
list.

46
00:01:58.870 --> 00:02:00.490 align:middle line:84%
And each of those
elements will then

47
00:02:00.490 --> 00:02:04.300 align:middle line:84%
be processed by a separate
worker thread or some worker

48
00:02:04.300 --> 00:02:06.640 align:middle line:84%
thread in the common
fork-joint pool.

49
00:02:06.640 --> 00:02:11.380 align:middle line:84%
So this is very efficient, very
fine-grain, and, as you'll see,

50
00:02:11.380 --> 00:02:14.480 align:middle line:84%
gives us this
wonderful speed-up.

51
00:02:14.480 --> 00:02:17.870 align:middle line:84%
Each input string that's
broken up using the spliterator

52
00:02:17.870 --> 00:02:21.043 align:middle line:84%
is processed in parallel using
the common fork-join pool.

53
00:02:21.043 --> 00:02:22.460 align:middle line:84%
And so we'll see
that, again, it's

54
00:02:22.460 --> 00:02:24.140 align:middle line:84%
very fine-grained
level of parallel.

55
00:02:24.140 --> 00:02:25.970 align:middle line:84%
So basically, each
work of Shakespeare

56
00:02:25.970 --> 00:02:28.520 align:middle line:84%
will have its own thread in
the pool that will get a chance

57
00:02:28.520 --> 00:02:32.260 align:middle line:90%
to run when it's time to run.

58
00:02:32.260 --> 00:02:34.450 align:middle line:84%
What then happens,
basically, like we

59
00:02:34.450 --> 00:02:37.840 align:middle line:84%
saw before, the map
intermediate operation gets

60
00:02:37.840 --> 00:02:41.730 align:middle line:84%
called, passing in the
processInput helper

61
00:02:41.730 --> 00:02:44.730 align:middle line:84%
method, which will then
turn around and search

62
00:02:44.730 --> 00:02:48.570 align:middle line:84%
that given input string to
locate all the phrases that we

63
00:02:48.570 --> 00:02:53.080 align:middle line:90%
care about in Hamlet or whatnot.

64
00:02:53.080 --> 00:02:58.020 align:middle line:84%
And then that will, of
course, come back with a list

65
00:02:58.020 --> 00:03:04.370 align:middle line:84%
or, rather, a stream of
lists of search results.

66
00:03:04.370 --> 00:03:08.060 align:middle line:84%
And then the collect terminal
operation gets called,

67
00:03:08.060 --> 00:03:10.820 align:middle line:84%
and it uses the
toList factory method

68
00:03:10.820 --> 00:03:12.890 align:middle line:84%
to return a non-concurrent
collector, which

69
00:03:12.890 --> 00:03:17.300 align:middle line:84%
obeys encounter order, and
will end up basically creating

70
00:03:17.300 --> 00:03:21.380 align:middle line:84%
a list of lists that merge
everything back together

71
00:03:21.380 --> 00:03:25.400 align:middle line:84%
and return that as the
result from processStream.

72
00:03:25.400 --> 00:03:26.863 align:middle line:90%
Pretty much the same as before.

73
00:03:26.863 --> 00:03:28.280 align:middle line:84%
Honestly, the only
real difference

74
00:03:28.280 --> 00:03:30.927 align:middle line:84%
here is the fact that
we changed stream

75
00:03:30.927 --> 00:03:33.260 align:middle line:84%
to parallelStream, just used
a different factory method.

76
00:03:33.260 --> 00:03:36.320 align:middle line:84%
And that's often-- not
always, but often--

77
00:03:36.320 --> 00:03:38.090 align:middle line:84%
the way things work
with parallelStream.

78
00:03:38.090 --> 00:03:40.663 align:middle line:84%
It's almost drop-dead easy to
go from a sequential stream

79
00:03:40.663 --> 00:03:42.080 align:middle line:84%
to a parallel
stream, which is one

80
00:03:42.080 --> 00:03:44.630 align:middle line:84%
of the virtues of this
functional programming

81
00:03:44.630 --> 00:03:46.570 align:middle line:90%
abstraction.

82
00:03:46.570 --> 00:03:49.120 align:middle line:84%
Let's take a quick
look at processInput.

83
00:03:49.120 --> 00:03:54.430 align:middle line:84%
As before, it also has
just one minuscule change.

84
00:03:54.430 --> 00:03:58.210 align:middle line:84%
It goes ahead and uses
parallelStream on the phrases

85
00:03:58.210 --> 00:04:02.230 align:middle line:84%
to find, which, once
again, uses the array list

86
00:04:02.230 --> 00:04:06.400 align:middle line:84%
spliterator to create a parallel
stream that will search a given

87
00:04:06.400 --> 00:04:08.560 align:middle line:84%
input string, a given
work of Shakespeare,

88
00:04:08.560 --> 00:04:12.490 align:middle line:84%
to locate all the
phrase occurrences.

89
00:04:12.490 --> 00:04:14.055 align:middle line:90%
I keep saying phase occurrences.

90
00:04:14.055 --> 00:04:14.930 align:middle line:90%
I've got to fix this.

91
00:04:14.930 --> 00:04:16.839 align:middle line:90%
Sorry about that.

92
00:04:16.839 --> 00:04:19.329 align:middle line:84%
As you can see here,
what we do when

93
00:04:19.329 --> 00:04:24.520 align:middle line:84%
we call the searchForPhrase
method in the context

94
00:04:24.520 --> 00:04:26.650 align:middle line:84%
of the lambda expression
passed into the map

95
00:04:26.650 --> 00:04:29.620 align:middle line:84%
intermediate
operation, we end up

96
00:04:29.620 --> 00:04:33.610 align:middle line:84%
passing the false parameter
as the fourth argument

97
00:04:33.610 --> 00:04:35.590 align:middle line:90%
to search for phrase.

98
00:04:35.590 --> 00:04:41.170 align:middle line:84%
And what that does is that
will use a sequential stream

99
00:04:41.170 --> 00:04:42.970 align:middle line:90%
to search for the phrase.

100
00:04:42.970 --> 00:04:45.520 align:middle line:84%
So it'll generate a
sequential stream of results.

101
00:04:45.520 --> 00:04:48.610 align:middle line:84%
When we come back later
in subsequent weeks

102
00:04:48.610 --> 00:04:52.180 align:middle line:84%
and talk about the
searchWithParallelSpliterator

103
00:04:52.180 --> 00:04:56.980 align:middle line:84%
example, you'll see how we'll
replace the false with true

104
00:04:56.980 --> 00:05:01.030 align:middle line:84%
here, which will cause
searchForPhrase to go ahead

105
00:05:01.030 --> 00:05:04.120 align:middle line:90%
and return a parallel stream.

106
00:05:04.120 --> 00:05:08.080 align:middle line:84%
So it'll do the searching
in even more fine degrees

107
00:05:08.080 --> 00:05:12.120 align:middle line:84%
of parallelization,
which is really cool.

108
00:05:12.120 --> 00:05:15.300 align:middle line:84%
Then, as you can see here, each
phrase in each input string

109
00:05:15.300 --> 00:05:19.600 align:middle line:84%
is processed in parallel in
the common fork-join pool.

110
00:05:19.600 --> 00:05:22.780 align:middle line:84%
And as before, we go
ahead and filter out

111
00:05:22.780 --> 00:05:24.910 align:middle line:84%
things that are
empty, we collect

112
00:05:24.910 --> 00:05:27.640 align:middle line:84%
the results back that triggers
the intermediate operation

113
00:05:27.640 --> 00:05:30.310 align:middle line:84%
processing, and then
merges all the results

114
00:05:30.310 --> 00:05:34.240 align:middle line:84%
into a single list of
search results, which

115
00:05:34.240 --> 00:05:37.000 align:middle line:84%
is what gets returned
as the result

116
00:05:37.000 --> 00:05:39.650 align:middle line:90%
of the processInput method.

117
00:05:39.650 --> 00:05:41.830 align:middle line:84%
So once again, just
to kind of recap this,

118
00:05:41.830 --> 00:05:43.870 align:middle line:84%
it's very much identical
to what we saw before,

119
00:05:43.870 --> 00:05:47.470 align:middle line:84%
with just those tiny,
minuscule changes

120
00:05:47.470 --> 00:05:50.190 align:middle line:84%
to go from stream
to parallel stream.