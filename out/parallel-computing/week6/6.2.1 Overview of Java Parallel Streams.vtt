WEBVTT

1
00:00:00.000 --> 00:00:00.630 align:middle line:90%


2
00:00:00.630 --> 00:00:05.580 align:middle line:84%
We're now ready to begin the
transition to parallelism.

3
00:00:05.580 --> 00:00:07.740 align:middle line:84%
In this part of the
lesson, I'll explain

4
00:00:07.740 --> 00:00:10.410 align:middle line:84%
how aggregate operations
from Java's sequential

5
00:00:10.410 --> 00:00:13.800 align:middle line:84%
streams that we've covered
in previous weeks are applied

6
00:00:13.800 --> 00:00:18.280 align:middle line:84%
in the context of the Java
parallel streams framework.

7
00:00:18.280 --> 00:00:20.500 align:middle line:90%
Just a quick recap from earlier.

8
00:00:20.500 --> 00:00:23.050 align:middle line:84%
Recall that a Java
stream is a pipeline

9
00:00:23.050 --> 00:00:26.770 align:middle line:84%
of aggregate operations that
process a sequence of elements,

10
00:00:26.770 --> 00:00:30.200 align:middle line:90%
also known as values or data.

11
00:00:30.200 --> 00:00:33.580 align:middle line:84%
These aggregate operations
use internal iteration

12
00:00:33.580 --> 00:00:36.440 align:middle line:84%
and behaviors to
process elements

13
00:00:36.440 --> 00:00:39.120 align:middle line:90%
that flow through a stream.

14
00:00:39.120 --> 00:00:42.660 align:middle line:84%
By default, a stream
execute sequentially.

15
00:00:42.660 --> 00:00:44.820 align:middle line:84%
So all of its
aggregate operations

16
00:00:44.820 --> 00:00:49.580 align:middle line:84%
run their behaviors in
one thread of control.

17
00:00:49.580 --> 00:00:52.750 align:middle line:84%
In contrast, when a stream
executes in parallel,

18
00:00:52.750 --> 00:00:57.050 align:middle line:84%
it is partitioned into multiple
substream chunks that run

19
00:00:57.050 --> 00:01:00.640 align:middle line:90%
in the common fork-join pool.

20
00:01:00.640 --> 00:01:04.090 align:middle line:84%
The threads in this fork-join
pool non-deterministically

21
00:01:04.090 --> 00:01:08.680 align:middle line:84%
process these different
chunks in parallel.

22
00:01:08.680 --> 00:01:10.840 align:middle line:84%
The intermediate
operations iterate over

23
00:01:10.840 --> 00:01:13.330 align:middle line:84%
and process the behaviors
on these chunks in parallel

24
00:01:13.330 --> 00:01:15.160 align:middle line:90%
as well.

25
00:01:15.160 --> 00:01:17.730 align:middle line:84%
And finally, the streams
terminal operation

26
00:01:17.730 --> 00:01:23.680 align:middle line:84%
is used to combine the chunks
into a single reduced result.

27
00:01:23.680 --> 00:01:26.280 align:middle line:84%
The stateless Java 8 lambda
expressions and method

28
00:01:26.280 --> 00:01:29.850 align:middle line:84%
references are used
to pass behaviors

29
00:01:29.850 --> 00:01:33.340 align:middle line:90%
into the aggregate operations.

30
00:01:33.340 --> 00:01:37.960 align:middle line:84%
Ideally, only minuscule changes
are needed to transition

31
00:01:37.960 --> 00:01:40.575 align:middle line:84%
from a sequential to
a parallel stream.

32
00:01:40.575 --> 00:01:41.950 align:middle line:84%
Although we'll
see later that you

33
00:01:41.950 --> 00:01:44.620 align:middle line:84%
can do more advanced
techniques in order

34
00:01:44.620 --> 00:01:47.590 align:middle line:84%
to ring even further
parallelism out

35
00:01:47.590 --> 00:01:49.810 align:middle line:84%
of your solutions,
which will ideally help

36
00:01:49.810 --> 00:01:51.610 align:middle line:84%
improve performance
even further.

37
00:01:51.610 --> 00:01:54.120 align:middle line:90%


38
00:01:54.120 --> 00:01:57.020 align:middle line:84%
The same aggregate operations
that we've talked about earlier

39
00:01:57.020 --> 00:02:00.020 align:middle line:84%
can be used for both sequential
and parallel streams.

40
00:02:00.020 --> 00:02:01.670 align:middle line:84%
And that's reassuring
because it means

41
00:02:01.670 --> 00:02:03.860 align:middle line:84%
all the things we've covered
in the previous weeks

42
00:02:03.860 --> 00:02:07.230 align:middle line:84%
don't have to be
relearned from scratch.

43
00:02:07.230 --> 00:02:10.910 align:middle line:84%
In particular, the
SearchStreamGang example case

44
00:02:10.910 --> 00:02:11.410 align:middle line:90%
study.

45
00:02:11.410 --> 00:02:15.600 align:middle line:84%
We've been focusing on uses
the same aggregate operations

46
00:02:15.600 --> 00:02:18.150 align:middle line:84%
for both the
SearchWithSequentialStreams

47
00:02:18.150 --> 00:02:21.660 align:middle line:84%
class and the
SearchWithParallelStreams class

48
00:02:21.660 --> 00:02:25.020 align:middle line:84%
that we'll be
looking at shortly.

49
00:02:25.020 --> 00:02:27.330 align:middle line:84%
Therefore, you can
treat parallelism

50
00:02:27.330 --> 00:02:29.760 align:middle line:84%
as an optimization
in Java streams

51
00:02:29.760 --> 00:02:32.730 align:middle line:84%
and use it to leverage
all of the available cores

52
00:02:32.730 --> 00:02:34.122 align:middle line:90%
at your disposal.

53
00:02:34.122 --> 00:02:35.580 align:middle line:84%
We'll also talk
later about how you

54
00:02:35.580 --> 00:02:38.162 align:middle line:84%
can limit the number of
cores that are used as well.

55
00:02:38.162 --> 00:02:39.870 align:middle line:84%
Although typically
you try to use as many

56
00:02:39.870 --> 00:02:41.310 align:middle line:84%
cause as possible
if your goal is

57
00:02:41.310 --> 00:02:45.480 align:middle line:84%
to get maximum throughput,
scalability, and latency out

58
00:02:45.480 --> 00:02:47.780 align:middle line:90%
of your solutions.

59
00:02:47.780 --> 00:02:49.590 align:middle line:84%
Naturally, the
behaviors that you

60
00:02:49.590 --> 00:02:51.990 align:middle line:84%
pass to the aggregate
operations have

61
00:02:51.990 --> 00:02:54.600 align:middle line:84%
to be very carefully
designed to avoid

62
00:02:54.600 --> 00:02:58.680 align:middle line:84%
accessing any unsynchronized
shared mutable state--

63
00:02:58.680 --> 00:03:00.840 align:middle line:84%
which, of course, is
the root of all evil

64
00:03:00.840 --> 00:03:02.670 align:middle line:84%
in parallel and
concurrent programs,

65
00:03:02.670 --> 00:03:04.895 align:middle line:84%
as we've talked
about many times.

66
00:03:04.895 --> 00:03:06.270 align:middle line:84%
In fact, we'll
also see, as we go

67
00:03:06.270 --> 00:03:09.990 align:middle line:84%
through these slides in this
lesson and other lessons,

68
00:03:09.990 --> 00:03:11.820 align:middle line:84%
that it's very
important to understand

69
00:03:11.820 --> 00:03:15.780 align:middle line:84%
how to avoid various parallelism
hazards by programming

70
00:03:15.780 --> 00:03:19.560 align:middle line:84%
properly to make sure you share
as little mutable state as

71
00:03:19.560 --> 00:03:20.530 align:middle line:90%
possible.

72
00:03:20.530 --> 00:03:22.080 align:middle line:90%
Ideally, none.