Not if you had a chance to Showcase and revisit the search with stream, gang case study and show how easy it was to go from sequential to parallel streams. It's a good time to take a step back and look at the internals of parallel streams. Have a better understanding of how things work under the hood. I gave you a quick synopsis of this earlier this week, but now I'm really going to go into more detail and really look in great depth about how Carol Streams works. If it's really, really fast name.
 As we talked about earlier and earlier weeks, when we discussed sequential stream internals, one of the first and most important things to understand, is what aspects of the parallel stream framework, you can change and what aspects? You can't change. You just have to come to grips with the fact, you can't change everything and then that's by Design. There's a lot of reasons. Why the parallel streams framework is designed and implemented the way it is, and you might quibble with some of the design choices, but I think you'll find a practice. It's it's really quite quite good, especially considering you don't have to write it documented, maintain it, the bucket and someone
 The first question of course is why do we care? Who cares, how I parallel streams Works? Shouldn't we just be happy? That it works so well, and in fact we've seen it. It's actually quite easy to to be parallel. So why do we do think some of the hood? Well, as you'll see very quickly, if you're just having fun, riding little demo program for teaching a class and it casually, it's probably not that important to know all the details internally. However, if you're trying to write performance critical applications, it's essential to understand how streams and parallel streams, work internally, because if you understand how it works you be more likely to use the right features in the right combinations. In order to get the right performance, that you need to meet your requirements.
 To start this discussion, just recall. There were three phases of a parallel stream. I'm not going to dwell on this, cuz we've covered it several times. But this sets up a discussion of what can change, what can't change. There's the splitting phase, where we use a splitter Raider to partition. The datastore stuff into multiple chunks is the apply phase where we independently process. These chunks in workers threads, and accounted for showing full Ellen. Finally have the combined phase, which joins the partial sub results and merge them together into a single reduced result.
 Now, it turns out that we can make some changes to splitting, we can make some changes to combining, but we're pretty much stuck with the way the apply phase works because there aren't many knobs for controlling The coming-forth Joint. Well, we'll see that. There's a few little simple knobs like influencing the number of threads or the 4th July pool, but you really can't control, for example, the order in which the processing takes place in parallel, that that's not something you really can control. So you got to come to grips with what you can control and then learn how to use those control, knobs effectively, to optimizing Junior code.