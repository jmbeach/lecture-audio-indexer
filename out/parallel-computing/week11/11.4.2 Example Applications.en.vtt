WEBVTT

1
00:00:00.000 --> 00:00:00.235 align:middle line:90%


2
00:00:00.235 --> 00:00:02.610 align:middle line:84%
So now that we've finished
giving an overview of the Test

3
00:00:02.610 --> 00:00:07.530 align:middle line:84%
Driver program, let's start by
talking about the applyAllIter

4
00:00:07.530 --> 00:00:09.000 align:middle line:90%
test method.

5
00:00:09.000 --> 00:00:14.130 align:middle line:84%
And this method uses "work
stealing" to disperse tasks

6
00:00:14.130 --> 00:00:15.660 align:middle line:90%
to worker threads.

7
00:00:15.660 --> 00:00:22.170 align:middle line:84%
And you can find the source code
in the ex22 folder in my GitHub

8
00:00:22.170 --> 00:00:24.380 align:middle line:90%
account.

9
00:00:24.380 --> 00:00:26.560 align:middle line:84%
So let's talk about how
this method is implemented.

10
00:00:26.560 --> 00:00:31.150 align:middle line:84%
This method will apply some
"op"-- which is a function--

11
00:00:31.150 --> 00:00:33.707 align:middle line:84%
to all the items in
a list it's given--

12
00:00:33.707 --> 00:00:35.290 align:middle line:84%
that list, of course,
will be the list

13
00:00:35.290 --> 00:00:38.290 align:middle line:84%
of all the big fractions
that we talked about before--

14
00:00:38.290 --> 00:00:43.720 align:middle line:84%
by calling the fork-join
methods iteratively

15
00:00:43.720 --> 00:00:45.600 align:middle line:90%
on the fork-join tasks.

16
00:00:45.600 --> 00:00:47.600 align:middle line:84%
So that's basically what
it's going to be doing,

17
00:00:47.600 --> 00:00:50.410 align:middle line:84%
and you'll see why this
ends up using work stealing

18
00:00:50.410 --> 00:00:52.780 align:middle line:84%
to get the information
distributed out

19
00:00:52.780 --> 00:00:56.270 align:middle line:84%
to the threads in
the worker pool.

20
00:00:56.270 --> 00:00:58.340 align:middle line:84%
The parameters that
are passed in here

21
00:00:58.340 --> 00:01:01.850 align:middle line:84%
are treated as "effectively
final" variables

22
00:01:01.850 --> 00:01:03.800 align:middle line:84%
in the anonymous
inner class below.

23
00:01:03.800 --> 00:01:05.690 align:middle line:84%
And the reason they're
effectively final

24
00:01:05.690 --> 00:01:09.950 align:middle line:84%
is that they don't change after
they're passed as parameters.

25
00:01:09.950 --> 00:01:11.750 align:middle line:84%
So even though they're
not marked as final,

26
00:01:11.750 --> 00:01:13.763 align:middle line:84%
they're effectively
final, which just

27
00:01:13.763 --> 00:01:15.680 align:middle line:84%
means that they don't
change between the point

28
00:01:15.680 --> 00:01:18.450 align:middle line:84%
where they're brought
into the method

29
00:01:18.450 --> 00:01:21.098 align:middle line:90%
and when they're actually used.

30
00:01:21.098 --> 00:01:22.390 align:middle line:90%
So here's what this looks like.

31
00:01:22.390 --> 00:01:25.620 align:middle line:84%
We're going to create an
anonymous recursive task

32
00:01:25.620 --> 00:01:31.560 align:middle line:84%
instance whose compute
method will iteratively

33
00:01:31.560 --> 00:01:35.650 align:middle line:90%
create many sub-tasks.

34
00:01:35.650 --> 00:01:38.200 align:middle line:84%
This code is sadly
somewhat verbose

35
00:01:38.200 --> 00:01:41.140 align:middle line:84%
due to the fact that the
fork-join pool appeared

36
00:01:41.140 --> 00:01:46.360 align:middle line:84%
in Java 7, the recursive task
is not a functional interface,

37
00:01:46.360 --> 00:01:49.420 align:middle line:84%
and, therefore, we can't
use lambdas here as we would

38
00:01:49.420 --> 00:01:52.300 align:middle line:84%
if this was done in
a more modern Java 8

39
00:01:52.300 --> 00:01:54.680 align:middle line:90%
and beyond programming stuff.

40
00:01:54.680 --> 00:01:56.060 align:middle line:84%
But we just have
to deal with it.

41
00:01:56.060 --> 00:01:58.518 align:middle line:84%
That's one of the reasons, by
the way, why some people like

42
00:01:58.518 --> 00:02:00.610 align:middle line:84%
to use the streams
framework because you

43
00:02:00.610 --> 00:02:02.500 align:middle line:84%
can use functional
programming mechanisms,

44
00:02:02.500 --> 00:02:05.110 align:middle line:84%
but we're stuck here
using the old school,

45
00:02:05.110 --> 00:02:08.320 align:middle line:84%
object-oriented
approaches instead.

46
00:02:08.320 --> 00:02:12.520 align:middle line:84%
The RecursiveTask that
we're creating here

47
00:02:12.520 --> 00:02:17.510 align:middle line:84%
is passed to the invoke
method on the fork-join pool.

48
00:02:17.510 --> 00:02:19.960 align:middle line:84%
And if you remember our
discussion of invoke

49
00:02:19.960 --> 00:02:24.550 align:middle line:84%
back in a previous week, when
we talked about the ForkJoinPool

50
00:02:24.550 --> 00:02:27.160 align:middle line:84%
class, you'll
remember that invoke

51
00:02:27.160 --> 00:02:30.580 align:middle line:84%
is a method that allows
non-fork-join task

52
00:02:30.580 --> 00:02:36.550 align:middle line:84%
clients to submit a fork-join
task into the fork-join pool.

53
00:02:36.550 --> 00:02:39.100 align:middle line:84%
And what this does
is it will invoke

54
00:02:39.100 --> 00:02:42.280 align:middle line:84%
this task in the fork-join
pool, and then it'll

55
00:02:42.280 --> 00:02:45.585 align:middle line:84%
block waiting for
the task to finish,

56
00:02:45.585 --> 00:02:47.210 align:middle line:84%
and then it'll return
the results back.

57
00:02:47.210 --> 00:02:49.690 align:middle line:84%
So this is a classic
blocking two-way call,

58
00:02:49.690 --> 00:02:52.420 align:middle line:84%
and that's exactly what we want
for our little test program

59
00:02:52.420 --> 00:02:53.080 align:middle line:90%
here.

60
00:02:53.080 --> 00:02:55.538 align:middle line:84%
Not always the right choice,
but for what we're doing here,

61
00:02:55.538 --> 00:02:57.500 align:middle line:90%
it's the right choice.

62
00:02:57.500 --> 00:03:00.210 align:middle line:84%
Here is the actual body
of the compute method

63
00:03:00.210 --> 00:03:03.060 align:middle line:84%
itself, which I have kind
of expanded out and left

64
00:03:03.060 --> 00:03:04.860 align:middle line:84%
out some of the
details surrounding it,

65
00:03:04.860 --> 00:03:08.140 align:middle line:84%
like the fact that it's
being passed to invoke.

66
00:03:08.140 --> 00:03:10.740 align:middle line:84%
So this is the
hook method that'll

67
00:03:10.740 --> 00:03:13.960 align:middle line:84%
get called back to implement
the main fork-join task.

68
00:03:13.960 --> 00:03:17.562 align:middle line:84%
This is the one that starts
all the wheels in motion.

69
00:03:17.562 --> 00:03:19.020 align:middle line:84%
You can see the
first thing that we

70
00:03:19.020 --> 00:03:24.480 align:middle line:84%
do is we create ourselves a new
LinkedList of fork-join tasks,

71
00:03:24.480 --> 00:03:27.860 align:middle line:84%
and we call that linked
list the forks list.

72
00:03:27.860 --> 00:03:30.690 align:middle line:84%
And then we also create
another LinkedList

73
00:03:30.690 --> 00:03:36.890 align:middle line:84%
of basically items t,
which will be the result.

74
00:03:36.890 --> 00:03:39.410 align:middle line:84%
So whatever the list of
t is that gets passed in,

75
00:03:39.410 --> 00:03:41.210 align:middle line:84%
we're going to end
up with results

76
00:03:41.210 --> 00:03:44.730 align:middle line:84%
after we apply the operation
to every item in the list.

77
00:03:44.730 --> 00:03:46.070 align:middle line:90%
So we have two lists.

78
00:03:46.070 --> 00:03:48.440 align:middle line:84%
Both of them are
treated as linked lists.

79
00:03:48.440 --> 00:03:51.110 align:middle line:84%
So res is the
results list, forks

80
00:03:51.110 --> 00:03:53.180 align:middle line:84%
is the list of fork-join
tasks that we're

81
00:03:53.180 --> 00:03:56.030 align:middle line:90%
going to go run in parallel.

82
00:03:56.030 --> 00:03:58.760 align:middle line:84%
We then go ahead and
use a for-each loop

83
00:03:58.760 --> 00:04:01.960 align:middle line:84%
to iterate through every
item in the list parameter.

84
00:04:01.960 --> 00:04:04.670 align:middle line:84%
Remember, those are all
of the randomly generated,

85
00:04:04.670 --> 00:04:08.550 align:middle line:90%
big fractions that we have.

86
00:04:08.550 --> 00:04:10.100 align:middle line:84%
And what we're
going to do is we're

87
00:04:10.100 --> 00:04:15.670 align:middle line:84%
going to create a new
anonymous RecursiveTask,

88
00:04:15.670 --> 00:04:19.570 align:middle line:84%
and we're going to have
its compute method applied

89
00:04:19.570 --> 00:04:23.830 align:middle line:84%
the function op that's
passed as a parameter

90
00:04:23.830 --> 00:04:28.570 align:middle line:84%
to every element
in the input list.

91
00:04:28.570 --> 00:04:34.473 align:middle line:84%
And it will then go ahead and
add that to the forks list.

92
00:04:34.473 --> 00:04:35.890 align:middle line:84%
And then the final
thing it'll do,

93
00:04:35.890 --> 00:04:38.560 align:middle line:84%
it'll go ahead and
fork off the task.

94
00:04:38.560 --> 00:04:41.440 align:middle line:84%
So what we're doing here is
we're basically forking off

95
00:04:41.440 --> 00:04:47.170 align:middle line:84%
the task, which arranges to
run it in the fork-join pool.

96
00:04:47.170 --> 00:04:50.230 align:middle line:84%
And we go ahead and add that
Recursive Task to the forecast

97
00:04:50.230 --> 00:04:52.370 align:middle line:84%
list so we can keep track
of it so we can join it,

98
00:04:52.370 --> 00:04:53.728 align:middle line:90%
which we'll do in just a moment.

99
00:04:53.728 --> 00:04:55.270 align:middle line:84%
Now, when fork gets
called, remember,

100
00:04:55.270 --> 00:04:57.750 align:middle line:84%
fork doesn't start the
wheels in motion immediately.

101
00:04:57.750 --> 00:05:04.322 align:middle line:84%
It simply cues up that task in
the deck of the calling thread.

102
00:05:04.322 --> 00:05:05.780 align:middle line:84%
So let's say, for
sake of argument,

103
00:05:05.780 --> 00:05:08.050 align:middle line:84%
we had a list with a
million items in it.

104
00:05:08.050 --> 00:05:09.820 align:middle line:84%
[CHUCKLES] That
will then go ahead

105
00:05:09.820 --> 00:05:11.500 align:middle line:84%
and throw every
one of those items

106
00:05:11.500 --> 00:05:18.490 align:middle line:84%
into the deck of that worker
thread in the fork-join pool.

107
00:05:18.490 --> 00:05:22.180 align:middle line:90%
They'll all be in one deck.

108
00:05:22.180 --> 00:05:24.100 align:middle line:84%
And of course,
this implementation

109
00:05:24.100 --> 00:05:27.490 align:middle line:84%
is going to rely on the
work stealing mechanism

110
00:05:27.490 --> 00:05:30.190 align:middle line:84%
to disperse these tasks
to the other worker

111
00:05:30.190 --> 00:05:33.430 align:middle line:84%
threads in the pool because
we don't want that one caller

112
00:05:33.430 --> 00:05:35.480 align:middle line:84%
worker thread to
process them all.

113
00:05:35.480 --> 00:05:38.560 align:middle line:84%
We want the other worker threads
to go ahead and steal them

114
00:05:38.560 --> 00:05:40.850 align:middle line:90%
and do their thing in parallel.

115
00:05:40.850 --> 00:05:43.670 align:middle line:84%
And that's exactly the
way this is going to work.

116
00:05:43.670 --> 00:05:46.210 align:middle line:84%
So after we do all
those forks, then we're

117
00:05:46.210 --> 00:05:48.610 align:middle line:84%
going to go ahead and
go into another loop

118
00:05:48.610 --> 00:05:53.120 align:middle line:84%
where we're going to loop
through the forks list.

119
00:05:53.120 --> 00:05:56.568 align:middle line:84%
So for each task in the
forks list-- remember,

120
00:05:56.568 --> 00:05:59.110 align:middle line:84%
we just forked all those things
and stuck them into the forks

121
00:05:59.110 --> 00:06:00.130 align:middle line:90%
list--

122
00:06:00.130 --> 00:06:04.630 align:middle line:84%
we're going to go ahead
and call the join method

123
00:06:04.630 --> 00:06:07.480 align:middle line:90%
on each of those tasks in turn.

124
00:06:07.480 --> 00:06:09.310 align:middle line:84%
And we'll refresh
your memory about what

125
00:06:09.310 --> 00:06:10.550 align:middle line:90%
join does in just a moment.

126
00:06:10.550 --> 00:06:13.540 align:middle line:84%
But when join returns, we
will take the result, which

127
00:06:13.540 --> 00:06:16.510 align:middle line:84%
will be the result of basically
reducing and multiplying

128
00:06:16.510 --> 00:06:19.390 align:middle line:84%
that large, random,
big fraction,

129
00:06:19.390 --> 00:06:23.380 align:middle line:84%
and we'll add it to
the res results list.

130
00:06:23.380 --> 00:06:24.760 align:middle line:90%
Now, remember how join works.

131
00:06:24.760 --> 00:06:27.760 align:middle line:84%
The way that join works is
when join us called on a task,

132
00:06:27.760 --> 00:06:30.580 align:middle line:84%
it doesn't actually
block the thread.

133
00:06:30.580 --> 00:06:36.580 align:middle line:84%
Instead, it has the thread
pitch in and run tasks

134
00:06:36.580 --> 00:06:38.980 align:middle line:84%
until it finds
the result that we

135
00:06:38.980 --> 00:06:42.130 align:middle line:84%
were trying to join with
when that task is finished.

136
00:06:42.130 --> 00:06:45.700 align:middle line:84%
So that's the Jiffy Lube
model of pitching in

137
00:06:45.700 --> 00:06:48.100 align:middle line:84%
and collaboratively
working to make

138
00:06:48.100 --> 00:06:51.050 align:middle line:90%
things work more effectively.

139
00:06:51.050 --> 00:06:53.480 align:middle line:84%
When the for loop
returns, that means

140
00:06:53.480 --> 00:06:55.280 align:middle line:84%
that all the results
have finished

141
00:06:55.280 --> 00:06:58.760 align:middle line:84%
and we've joined, and gotten
their values back, and added

142
00:06:58.760 --> 00:07:00.220 align:middle line:90%
them to the results list.

143
00:07:00.220 --> 00:07:01.880 align:middle line:84%
And then we go
ahead and pass back

144
00:07:01.880 --> 00:07:05.690 align:middle line:84%
the results list as the
parameter from the applyAllIter

145
00:07:05.690 --> 00:07:06.900 align:middle line:90%
method.

146
00:07:06.900 --> 00:07:07.400 align:middle line:90%
OK.

147
00:07:07.400 --> 00:07:09.380 align:middle line:84%
So that's kind of
how things work.

148
00:07:09.380 --> 00:07:11.150 align:middle line:84%
This implementation,
I think you'll agree,

149
00:07:11.150 --> 00:07:15.290 align:middle line:84%
is very simple to program
and understand since it's

150
00:07:15.290 --> 00:07:18.320 align:middle line:90%
inherently iterative.

151
00:07:18.320 --> 00:07:20.000 align:middle line:84%
Let's visualize how
this thing works

152
00:07:20.000 --> 00:07:23.080 align:middle line:84%
because it's pretty important
to understand the big picture.

153
00:07:23.080 --> 00:07:25.100 align:middle line:84%
And this will also show
you this whole concept

154
00:07:25.100 --> 00:07:26.990 align:middle line:90%
about using work stealing.

155
00:07:26.990 --> 00:07:29.300 align:middle line:84%
So here's the
applyAllIter method.

156
00:07:29.300 --> 00:07:31.730 align:middle line:84%
And over here, I show
you the ForkJoinPool

157
00:07:31.730 --> 00:07:33.512 align:middle line:90%
with its shared queue.

158
00:07:33.512 --> 00:07:35.720 align:middle line:84%
And when the invoke method
is first called, remember,

159
00:07:35.720 --> 00:07:38.960 align:middle line:84%
that's a way to enable
a non-fork-join task

160
00:07:38.960 --> 00:07:44.120 align:middle line:84%
client to insert a task into
the ForkJoinPool's shared queue.

161
00:07:44.120 --> 00:07:49.100 align:middle line:84%
So that goes out and puts that
initial anonymous inner class

162
00:07:49.100 --> 00:07:52.530 align:middle line:90%
task into the shared queue.

163
00:07:52.530 --> 00:07:58.080 align:middle line:84%
What then happens is one of the
threads in that ForkJoinPool--

164
00:07:58.080 --> 00:07:59.940 align:middle line:90%
let's call it WT1--

165
00:07:59.940 --> 00:08:04.950 align:middle line:84%
will go ahead and start to
compute that initial task.

166
00:08:04.950 --> 00:08:07.470 align:middle line:84%
It'll get it from the shared
queue and start to compute it.

167
00:08:07.470 --> 00:08:09.960 align:middle line:84%
And there, as you can see,
it runs that for loop.

168
00:08:09.960 --> 00:08:11.550 align:middle line:84%
And what that for
loop does, as we

169
00:08:11.550 --> 00:08:13.740 align:middle line:84%
talked about when
we analyze the code,

170
00:08:13.740 --> 00:08:18.840 align:middle line:84%
is it goes ahead and forks all
the various tasks or sub-tasks

171
00:08:18.840 --> 00:08:22.140 align:middle line:84%
and sticks them into
the that worker thread's

172
00:08:22.140 --> 00:08:24.990 align:middle line:90%
deck-- the WT1'S deck.

173
00:08:24.990 --> 00:08:28.290 align:middle line:84%
And so all those
things are in the deck.

174
00:08:28.290 --> 00:08:31.135 align:middle line:90%
And this is the compute method.

175
00:08:31.135 --> 00:08:33.510 align:middle line:84%
This is the part that's doing
that the original recursive

176
00:08:33.510 --> 00:08:35.260 align:middle line:90%
task's compute method.

177
00:08:35.260 --> 00:08:37.740 align:middle line:84%
So now we have a deck
full of these sub-tasks--

178
00:08:37.740 --> 00:08:40.200 align:middle line:84%
all the sub-tasks
we're going to run.

179
00:08:40.200 --> 00:08:42.450 align:middle line:90%
So what happens at this point?

180
00:08:42.450 --> 00:08:45.570 align:middle line:84%
Does everything just run
in WT1, in that thread?

181
00:08:45.570 --> 00:08:46.587 align:middle line:90%
Of course not.

182
00:08:46.587 --> 00:08:49.170 align:middle line:84%
What's going to happen is that
the other threads in the pool--

183
00:08:49.170 --> 00:08:52.680 align:middle line:84%
WT2, WT3, whichever
ones they are--

184
00:08:52.680 --> 00:08:56.280 align:middle line:84%
will say, hey, I'm
just sitting here idle.

185
00:08:56.280 --> 00:08:58.600 align:middle line:84%
I want to do some
work, so I'm going

186
00:08:58.600 --> 00:09:05.070 align:middle line:84%
to go ahead and steal tasks
off of the deck of WT1.

187
00:09:05.070 --> 00:09:10.350 align:middle line:84%
And I will start to process
them in my thread-- in my deck.

188
00:09:10.350 --> 00:09:13.755 align:middle line:84%
And so it goes ahead and steals
the threads, steals the tasks,

189
00:09:13.755 --> 00:09:15.630 align:middle line:84%
and then starts to have
the other threads run

190
00:09:15.630 --> 00:09:18.190 align:middle line:90%
those tasks in parallel.

191
00:09:18.190 --> 00:09:20.580 align:middle line:84%
So the key thing to note here,
from a kind of comparison

192
00:09:20.580 --> 00:09:23.310 align:middle line:84%
point of view, is that
work stealing overhead

193
00:09:23.310 --> 00:09:25.715 align:middle line:84%
is high because we put
everything in one deck

194
00:09:25.715 --> 00:09:26.215 align:middle line:90%
originally.

195
00:09:26.215 --> 00:09:28.440 align:middle line:84%
So we got to steal
a lot of stuff.

196
00:09:28.440 --> 00:09:31.470 align:middle line:84%
But copying and
method call overhead

197
00:09:31.470 --> 00:09:33.720 align:middle line:84%
is very low because we're
just getting this stuff,

198
00:09:33.720 --> 00:09:36.760 align:middle line:90%
and away we go.

199
00:09:36.760 --> 00:09:40.570 align:middle line:84%
The worker threads will all
pitch in when join is called,

200
00:09:40.570 --> 00:09:43.120 align:middle line:84%
and they'll also
run other tasks.

201
00:09:43.120 --> 00:09:46.720 align:middle line:84%
And when their particular
task that they're joining with

202
00:09:46.720 --> 00:09:50.650 align:middle line:84%
gets a result, they will return,
add the result to the results

203
00:09:50.650 --> 00:09:53.475 align:middle line:90%
list, and away we go.

204
00:09:53.475 --> 00:09:55.100 align:middle line:84%
So that's the
collaborative, Jiffy Lube

205
00:09:55.100 --> 00:10:00.010 align:middle line:84%
model of pitching in and
being a good employee.

206
00:10:00.010 --> 00:10:03.640 align:middle line:84%
This particular loop here--
the one that does the joining--

207
00:10:03.640 --> 00:10:06.730 align:middle line:84%
implements what we know as
"barrier synchronization"

208
00:10:06.730 --> 00:10:12.460 align:middle line:84%
because it effectively blocks
the progress of this program

209
00:10:12.460 --> 00:10:16.450 align:middle line:84%
until all the tasks
have finished.

210
00:10:16.450 --> 00:10:19.060 align:middle line:84%
And we've talked about
various synchronization

211
00:10:19.060 --> 00:10:21.460 align:middle line:84%
at length in our concurrent
object-oriented programming

212
00:10:21.460 --> 00:10:23.010 align:middle line:90%
course.