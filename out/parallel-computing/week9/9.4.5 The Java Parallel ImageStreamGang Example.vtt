WEBVTT

1
00:00:00.000 --> 00:00:00.007 align:middle line:90%


2
00:00:00.007 --> 00:00:01.590 align:middle line:84%
So now that we've
had a chance to talk

3
00:00:01.590 --> 00:00:05.040 align:middle line:84%
about the parallel
ImageStreamGang example, let's

4
00:00:05.040 --> 00:00:07.350 align:middle line:84%
take some time to
evaluate the pros

5
00:00:07.350 --> 00:00:10.050 align:middle line:90%
and cons with this approach.

6
00:00:10.050 --> 00:00:12.630 align:middle line:84%
And one of the things
you can see right away

7
00:00:12.630 --> 00:00:16.770 align:middle line:84%
is that the parallel streams
version is always faster

8
00:00:16.770 --> 00:00:18.690 align:middle line:84%
than the sequential
streams version,

9
00:00:18.690 --> 00:00:20.250 align:middle line:90%
no real surprise there.

10
00:00:20.250 --> 00:00:24.450 align:middle line:84%
This is using my
Windows computer

11
00:00:24.450 --> 00:00:27.030 align:middle line:90%
with 64 gigabytes of memory.

12
00:00:27.030 --> 00:00:32.090 align:middle line:84%
This is my sixth core
computer running on Intel,

13
00:00:32.090 --> 00:00:36.720 align:middle line:84%
I think it's an i9 processor,
and running Windows on Lenovo.

14
00:00:36.720 --> 00:00:38.530 align:middle line:84%
So you can see you
get a good speed

15
00:00:38.530 --> 00:00:43.250 align:middle line:84%
up by using parallel
streams in that environment.

16
00:00:43.250 --> 00:00:44.990 align:middle line:84%
The images are
downloaded and processed

17
00:00:44.990 --> 00:00:46.640 align:middle line:84%
in parallel on the
multiple cores.

18
00:00:46.640 --> 00:00:48.980 align:middle line:90%
So that's obviously a win.

19
00:00:48.980 --> 00:00:51.170 align:middle line:84%
I think it's also
probably fair to say

20
00:00:51.170 --> 00:00:56.280 align:middle line:84%
that the solution is relatively
straightforward to understand.

21
00:00:56.280 --> 00:00:59.720 align:middle line:84%
So if you take a look at
this, as I mentioned before,

22
00:00:59.720 --> 00:01:02.780 align:middle line:84%
it kind of maps almost
one-to-one onto the design

23
00:01:02.780 --> 00:01:03.930 align:middle line:90%
intent.

24
00:01:03.930 --> 00:01:06.350 align:middle line:84%
We're going to get
a list of URLs.

25
00:01:06.350 --> 00:01:08.893 align:middle line:84%
We're going to filter out the
ones that are already cached.

26
00:01:08.893 --> 00:01:11.060 align:middle line:84%
We're going to download the
ones that aren't cached.

27
00:01:11.060 --> 00:01:12.685 align:middle line:84%
We're going to apply
the image filters.

28
00:01:12.685 --> 00:01:14.580 align:middle line:84%
And we're going to
display the results.

29
00:01:14.580 --> 00:01:16.550 align:middle line:84%
So pretty much
one-to-one mapping

30
00:01:16.550 --> 00:01:18.630 align:middle line:84%
onto the explanation
of the behavior.

31
00:01:18.630 --> 00:01:22.910 align:middle line:84%
So it closes that gap between
design intent on the one hand

32
00:01:22.910 --> 00:01:27.290 align:middle line:84%
and on the other hand, the
computations you have to write

33
00:01:27.290 --> 00:01:30.620 align:middle line:90%
are very much almost one-to-one.

34
00:01:30.620 --> 00:01:32.930 align:middle line:84%
Another nice thing about
this particular design

35
00:01:32.930 --> 00:01:36.440 align:middle line:84%
is that all the behaviors
are synchronous.

36
00:01:36.440 --> 00:01:39.800 align:middle line:84%
What that means is that the
callee, the thread that's

37
00:01:39.800 --> 00:01:43.670 align:middle line:84%
called, borrows the
thread of the caller

38
00:01:43.670 --> 00:01:45.810 align:middle line:90%
while the call is taking place.

39
00:01:45.810 --> 00:01:47.120 align:middle line:90%
So we can check the cache.

40
00:01:47.120 --> 00:01:50.510 align:middle line:84%
That causes the caller thread to
block till we check the cache.

41
00:01:50.510 --> 00:01:51.530 align:middle line:90%
We download the image.

42
00:01:51.530 --> 00:01:54.170 align:middle line:84%
That causes the caller thread to
block while we check the image

43
00:01:54.170 --> 00:01:55.580 align:middle line:90%
and get the result back.

44
00:01:55.580 --> 00:01:59.710 align:middle line:84%
And it's very easy to reason
about synchronous calls.

45
00:01:59.710 --> 00:02:00.950 align:middle line:90%
They're not mysterious.

46
00:02:00.950 --> 00:02:05.270 align:middle line:84%
We've all programmed with sort
of this two way invocation

47
00:02:05.270 --> 00:02:08.690 align:middle line:84%
return method call
model for decades.

48
00:02:08.690 --> 00:02:11.060 align:middle line:84%
That's the way almost
everybody I know,

49
00:02:11.060 --> 00:02:15.300 align:middle line:84%
including myself, learned
how to write code originally.

50
00:02:15.300 --> 00:02:18.120 align:middle line:84%
Another nice thing is
that the flow of control

51
00:02:18.120 --> 00:02:21.240 align:middle line:84%
here can be read
in a linear manner.

52
00:02:21.240 --> 00:02:22.480 align:middle line:90%
I can start at the top.

53
00:02:22.480 --> 00:02:24.420 align:middle line:84%
I can say I've got
myself a stream.

54
00:02:24.420 --> 00:02:25.260 align:middle line:90%
I do some filtering.

55
00:02:25.260 --> 00:02:26.010 align:middle line:90%
I do some mapping.

56
00:02:26.010 --> 00:02:27.510 align:middle line:90%
I do some flat mapping.

57
00:02:27.510 --> 00:02:28.770 align:middle line:90%
And there's no loops.

58
00:02:28.770 --> 00:02:29.880 align:middle line:90%
There's no if statements.

59
00:02:29.880 --> 00:02:31.350 align:middle line:90%
There's no switch statements.

60
00:02:31.350 --> 00:02:34.530 align:middle line:84%
It just is very
straightforward linear code.

61
00:02:34.530 --> 00:02:36.750 align:middle line:84%
And I also find that
to be very comforting.

62
00:02:36.750 --> 00:02:38.940 align:middle line:84%
You don't have to
sit there and try

63
00:02:38.940 --> 00:02:42.420 align:middle line:84%
to play runtime assembly
code execution engine

64
00:02:42.420 --> 00:02:45.370 align:middle line:90%
in your head, which is good.

65
00:02:45.370 --> 00:02:47.830 align:middle line:84%
Of course, there
are some downsides.

66
00:02:47.830 --> 00:02:51.460 align:middle line:84%
One of the obvious downsides
is that the computable futures

67
00:02:51.460 --> 00:02:55.440 align:middle line:84%
versions are faster than the
parallel streams versions.

68
00:02:55.440 --> 00:02:55.940 align:middle line:90%
Whoa!

69
00:02:55.940 --> 00:02:57.400 align:middle line:90%
What's going on here?

70
00:02:57.400 --> 00:02:59.410 align:middle line:84%
Well, it turns out,
for various reasons,

71
00:02:59.410 --> 00:03:02.230 align:middle line:84%
that under these scenarios
with this platform,

72
00:03:02.230 --> 00:03:05.290 align:middle line:84%
and the amount of memory
I have, and the cores,

73
00:03:05.290 --> 00:03:08.080 align:middle line:84%
and the versions of the Java
virtual machine I'm running,

74
00:03:08.080 --> 00:03:10.060 align:middle line:84%
and the way in which I'm
doing the processing,

75
00:03:10.060 --> 00:03:11.860 align:middle line:84%
that completable
futures just happen

76
00:03:11.860 --> 00:03:14.920 align:middle line:84%
to have less overhead
to do their thing

77
00:03:14.920 --> 00:03:16.990 align:middle line:90%
than parallel streams.

78
00:03:16.990 --> 00:03:19.960 align:middle line:84%
Other scenarios might have
different performance results.

79
00:03:19.960 --> 00:03:24.040 align:middle line:84%
It all depends on
various properties.

80
00:03:24.040 --> 00:03:28.720 align:middle line:84%
However, there's a trade off
between computing performance

81
00:03:28.720 --> 00:03:32.740 align:middle line:84%
on the one hand and
programmer productivity

82
00:03:32.740 --> 00:03:36.550 align:middle line:84%
on the other when choosing
amongst these different Java

83
00:03:36.550 --> 00:03:38.390 align:middle line:90%
parallelism frameworks.

84
00:03:38.390 --> 00:03:40.630 align:middle line:84%
So as a general rule
of thumb, which you'll

85
00:03:40.630 --> 00:03:42.562 align:middle line:84%
have to accept on faith
right now and then

86
00:03:42.562 --> 00:03:45.145 align:middle line:84%
we'll come back later and I'll
hopefully demonstrate it to you

87
00:03:45.145 --> 00:03:47.900 align:middle line:84%
more conclusively when we talk
about completable futures.

88
00:03:47.900 --> 00:03:50.320 align:middle line:84%
Completable futures are
more efficient and scalable

89
00:03:50.320 --> 00:03:51.820 align:middle line:90%
than parallel streams.

90
00:03:51.820 --> 00:03:54.700 align:middle line:84%
But they're somewhat
harder to program.

91
00:03:54.700 --> 00:03:56.350 align:middle line:84%
And that's because
asynchrony models

92
00:03:56.350 --> 00:03:58.510 align:middle line:84%
are just a little bit less
intuitive to most people

93
00:03:58.510 --> 00:04:01.560 align:middle line:84%
or maybe a lot less
intuitive to most people.

94
00:04:01.560 --> 00:04:03.970 align:middle line:84%
So that's the end
of this discussion.

95
00:04:03.970 --> 00:04:07.290 align:middle line:84%
I hope you enjoyed this
particular example.

96
00:04:07.290 --> 00:04:08.950 align:middle line:90%
I had a lot of fun writing it.

97
00:04:08.950 --> 00:04:10.530 align:middle line:84%
And I think you'll
have a lot of fun

98
00:04:10.530 --> 00:04:12.810 align:middle line:84%
using it as an example
for other things

99
00:04:12.810 --> 00:04:15.680 align:middle line:84%
that we do in this
class and beyond.