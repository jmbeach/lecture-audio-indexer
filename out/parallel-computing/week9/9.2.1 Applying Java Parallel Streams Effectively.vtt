WEBVTT

1
00:00:00.000 --> 00:00:00.090 align:middle line:90%


2
00:00:00.090 --> 00:00:01.590 align:middle line:84%
Now that you've had
a chance to talk

3
00:00:01.590 --> 00:00:05.490 align:middle line:84%
through several variants of the
search stream gang case study,

4
00:00:05.490 --> 00:00:07.560 align:middle line:84%
search with parallel
streams, and search

5
00:00:07.560 --> 00:00:09.750 align:middle line:84%
with parallel spliterators,
let's go ahead

6
00:00:09.750 --> 00:00:12.720 align:middle line:84%
and talk about a broader,
more important issue--

7
00:00:12.720 --> 00:00:14.850 align:middle line:84%
when to use Java
parallel streams

8
00:00:14.850 --> 00:00:17.200 align:middle line:90%
and when not to use them.

9
00:00:17.200 --> 00:00:21.470 align:middle line:84%
We'll start by discussing
when to use parallel streams.

10
00:00:21.470 --> 00:00:26.090 align:middle line:84%
It's important to recognize that
parallelism is not a panacea.

11
00:00:26.090 --> 00:00:30.290 align:middle line:84%
In particular, a parallel
program always does more work

12
00:00:30.290 --> 00:00:32.720 align:middle line:90%
than a nonparallel program.

13
00:00:32.720 --> 00:00:34.520 align:middle line:84%
For example, a
parallel program needs

14
00:00:34.520 --> 00:00:37.790 align:middle line:84%
to partition the overall
task to be performed

15
00:00:37.790 --> 00:00:40.250 align:middle line:90%
into various subtasks.

16
00:00:40.250 --> 00:00:42.020 align:middle line:84%
We see how things
like spliterators

17
00:00:42.020 --> 00:00:45.160 align:middle line:84%
are used to do that with
Java parallel streams.

18
00:00:45.160 --> 00:00:48.640 align:middle line:84%
It then needs take the chunks
produced from the splitting

19
00:00:48.640 --> 00:00:53.320 align:middle line:84%
phase and apply them to
process all the subtasks.

20
00:00:53.320 --> 00:00:56.680 align:middle line:84%
This step is typically all
that a sequential program does.

21
00:00:56.680 --> 00:00:59.470 align:middle line:90%
It just does the processing.

22
00:00:59.470 --> 00:01:02.830 align:middle line:84%
And then third, it needs
to combine the results

23
00:01:02.830 --> 00:01:08.750 align:middle line:84%
from the various subtasks
into a final reduced result.

24
00:01:08.750 --> 00:01:11.180 align:middle line:84%
Step number one and
step number three

25
00:01:11.180 --> 00:01:14.240 align:middle line:84%
are additional work
that needn't be

26
00:01:14.240 --> 00:01:17.645 align:middle line:90%
done by a sequential program.

27
00:01:17.645 --> 00:01:19.020 align:middle line:84%
Therefore, there
better darn well

28
00:01:19.020 --> 00:01:21.210 align:middle line:84%
be a benefit from
doing this in parallel.

29
00:01:21.210 --> 00:01:24.510 align:middle line:84%
Otherwise, we're going to swamp
ourselves with this splitting

30
00:01:24.510 --> 00:01:27.270 align:middle line:90%
and combining cost.

31
00:01:27.270 --> 00:01:30.450 align:middle line:84%
So therefore, you have to
think through carefully

32
00:01:30.450 --> 00:01:33.120 align:middle line:84%
whether it makes sense
to use parallel streams

33
00:01:33.120 --> 00:01:35.580 align:middle line:84%
or not, and that's because
previous streams are

34
00:01:35.580 --> 00:01:39.850 align:middle line:84%
useful in some, but by
no means all, conditions.

35
00:01:39.850 --> 00:01:43.260 align:middle line:84%
So let's talk about when
to use parallel streams.

36
00:01:43.260 --> 00:01:47.790 align:middle line:84%
Parallel streams are most
useful under certain conditions.

37
00:01:47.790 --> 00:01:50.160 align:middle line:84%
One set of conditions
are when behaviors--

38
00:01:50.160 --> 00:01:54.500 align:middle line:84%
the processing that takes place,
for example, in a Java Stream--

39
00:01:54.500 --> 00:01:57.420 align:middle line:90%
have certain characteristics.

40
00:01:57.420 --> 00:01:59.620 align:middle line:90%
One, they're independent.

41
00:01:59.620 --> 00:02:02.940 align:middle line:84%
The processing tasks
are going to work best

42
00:02:02.940 --> 00:02:06.360 align:middle line:84%
if they have little or no
dependencies between each other

43
00:02:06.360 --> 00:02:09.750 align:middle line:84%
and no need to communicate or
share results between them.

44
00:02:09.750 --> 00:02:12.270 align:middle line:84%
If tasks have those
properties, we typically

45
00:02:12.270 --> 00:02:14.830 align:middle line:84%
call them
embarrassingly parallel.

46
00:02:14.830 --> 00:02:16.740 align:middle line:84%
And I've used this
example multiple times

47
00:02:16.740 --> 00:02:20.280 align:middle line:84%
now of going to the laundromat
and washing all your clothes

48
00:02:20.280 --> 00:02:23.430 align:middle line:84%
in a bank of washers and
drying all your clothes

49
00:02:23.430 --> 00:02:25.860 align:middle line:84%
in a bank of dryers, and the
nice thing about that is they

50
00:02:25.860 --> 00:02:29.010 align:middle line:84%
don't depend on each other and
they can just run in parallel.

51
00:02:29.010 --> 00:02:31.860 align:middle line:84%
You'll probably spend a lot of
quarters, if you're in the US,

52
00:02:31.860 --> 00:02:37.130 align:middle line:84%
but you'll get things done and
you'll get it done quickly.

53
00:02:37.130 --> 00:02:39.050 align:middle line:84%
We've shown a number
of examples that

54
00:02:39.050 --> 00:02:40.630 align:middle line:90%
fit this bill quite nicely.

55
00:02:40.630 --> 00:02:42.860 align:middle line:84%
For example,
searching for phrases

56
00:02:42.860 --> 00:02:45.140 align:middle line:90%
in a list of input strings--

57
00:02:45.140 --> 00:02:47.600 align:middle line:84%
the works of Shakespeare,
or the song lyrics,

58
00:02:47.600 --> 00:02:48.800 align:middle line:90%
or whatever you want to do--

59
00:02:48.800 --> 00:02:50.390 align:middle line:84%
those are all things
where the tasks

60
00:02:50.390 --> 00:02:52.984 align:middle line:90%
are fundamentally independent.

61
00:02:52.984 --> 00:02:55.770 align:middle line:90%


62
00:02:55.770 --> 00:02:57.660 align:middle line:84%
For example, we use
parallel streams

63
00:02:57.660 --> 00:03:00.390 align:middle line:84%
to search for each
phrase in parallel,

64
00:03:00.390 --> 00:03:02.520 align:middle line:84%
search for each input
string in parallel,

65
00:03:02.520 --> 00:03:05.200 align:middle line:84%
and search for chunks in each
input string in parallel.

66
00:03:05.200 --> 00:03:07.540 align:middle line:84%
So we had different variants
that did those things.

67
00:03:07.540 --> 00:03:12.090 align:middle line:84%
And as we saw, the search with
parallel spliterator example

68
00:03:12.090 --> 00:03:16.870 align:middle line:84%
is the most aggressive approach
and it tends to work the best.

69
00:03:16.870 --> 00:03:18.580 align:middle line:84%
Another characteristic
that lends itself

70
00:03:18.580 --> 00:03:23.620 align:middle line:84%
nicely to parallelization is
how computationally expensive

71
00:03:23.620 --> 00:03:26.140 align:middle line:84%
the processing is
done on each element.

72
00:03:26.140 --> 00:03:29.170 align:middle line:84%
When the behaviors are
applied to each element

73
00:03:29.170 --> 00:03:33.460 align:middle line:84%
take a long time to run, we're
likely to see better results

74
00:03:33.460 --> 00:03:38.430 align:middle line:84%
from throwing parallel
processing at the problem.

75
00:03:38.430 --> 00:03:40.980 align:middle line:84%
Another related
dimension is how many

76
00:03:40.980 --> 00:03:43.950 align:middle line:84%
elements are going
to be processed

77
00:03:43.950 --> 00:03:46.020 align:middle line:90%
as part of the data sources?

78
00:03:46.020 --> 00:03:48.780 align:middle line:84%
Again, if you have lots
of elements to process,

79
00:03:48.780 --> 00:03:51.090 align:middle line:84%
then parallelism is often
a win, whereas if you only

80
00:03:51.090 --> 00:03:53.010 align:middle line:84%
have a handful, it's
probably overkill.

81
00:03:53.010 --> 00:03:55.920 align:middle line:84%
You'll get swamped by
splitting and combining costs.

82
00:03:55.920 --> 00:03:58.760 align:middle line:90%


83
00:03:58.760 --> 00:04:01.400 align:middle line:84%
As we've seen a number of
times and have demonstrated

84
00:04:01.400 --> 00:04:05.200 align:middle line:84%
empirically through
some tests, parallelism

85
00:04:05.200 --> 00:04:08.860 align:middle line:84%
works best in the Streams
model when the sources of input

86
00:04:08.860 --> 00:04:12.130 align:middle line:84%
can be split evenly
and efficiently.

87
00:04:12.130 --> 00:04:14.542 align:middle line:90%
Ideally, split in half.

88
00:04:14.542 --> 00:04:16.000 align:middle line:84%
So if you take
these two elements--

89
00:04:16.000 --> 00:04:18.820 align:middle line:84%
computationally expensive
and applied to many elements

90
00:04:18.820 --> 00:04:20.260 align:middle line:90%
of the data sources--

91
00:04:20.260 --> 00:04:22.690 align:middle line:84%
we end up with something
called the N times Q model,

92
00:04:22.690 --> 00:04:24.910 align:middle line:84%
or the NQ model,
which is described

93
00:04:24.910 --> 00:04:28.040 align:middle line:84%
in a number of places, this
link being one of them.

94
00:04:28.040 --> 00:04:30.550 align:middle line:84%
In this model, N is the
number of data elements

95
00:04:30.550 --> 00:04:32.710 align:middle line:84%
that are going to be
processed, either per thread

96
00:04:32.710 --> 00:04:37.180 align:middle line:84%
or for the whole
multicore platform.

97
00:04:37.180 --> 00:04:41.230 align:middle line:84%
And Q is a quantification of
how CPU-intensive the processing

98
00:04:41.230 --> 00:04:42.040 align:middle line:90%
is.

99
00:04:42.040 --> 00:04:44.530 align:middle line:84%
So as shown by this
little chart here,

100
00:04:44.530 --> 00:04:48.130 align:middle line:84%
the larger N is and
the higher Q is,

101
00:04:48.130 --> 00:04:51.370 align:middle line:84%
that's the ideal for
doing parallel processing.

102
00:04:51.370 --> 00:04:53.630 align:middle line:84%
In contrast, if you
have low N and low

103
00:04:53.630 --> 00:04:55.850 align:middle line:90%
Q, probably not worth it.

104
00:04:55.850 --> 00:04:57.940 align:middle line:84%
And there's some break
even point somewhere.

105
00:04:57.940 --> 00:05:00.760 align:middle line:84%
You'd probably be well
advised to search for it

106
00:05:00.760 --> 00:05:02.830 align:middle line:90%
by doing some empirical tests.

107
00:05:02.830 --> 00:05:06.070 align:middle line:84%
Brian Getz likes to say,
if N times Q equals 10,000,

108
00:05:06.070 --> 00:05:08.840 align:middle line:84%
then you're probably better
off using a parallel stream.

109
00:05:08.840 --> 00:05:11.290 align:middle line:84%
I'm not sure if 10,000 is
quite exactly the right number,

110
00:05:11.290 --> 00:05:14.200 align:middle line:84%
but it's just a good heuristic
to say as it gets bigger,

111
00:05:14.200 --> 00:05:18.940 align:middle line:84%
you're going to get a better win
from using parallel computing.

112
00:05:18.940 --> 00:05:20.680 align:middle line:84%
We saw this, where
we were searching

113
00:05:20.680 --> 00:05:23.270 align:middle line:84%
for phrases that match in
the works of Shakespeare.

114
00:05:23.270 --> 00:05:26.240 align:middle line:84%
So the searching was fairly
computationally expensive.

115
00:05:26.240 --> 00:05:28.330 align:middle line:84%
Searching the input
strings to find

116
00:05:28.330 --> 00:05:31.330 align:middle line:84%
matches with regular
expressions take some time.

117
00:05:31.330 --> 00:05:33.280 align:middle line:84%
And we had lots of
things to search,

118
00:05:33.280 --> 00:05:35.480 align:middle line:90%
lots of works of Shakespeare.

119
00:05:35.480 --> 00:05:38.890 align:middle line:84%
Of course, even there, you
can imagine lots of data sets

120
00:05:38.890 --> 00:05:41.650 align:middle line:84%
would have way more
than 38 elements in them

121
00:05:41.650 --> 00:05:44.440 align:middle line:84%
and we'd be doing even more
intense processing than just

122
00:05:44.440 --> 00:05:46.870 align:middle line:84%
searching texts to try to
find regular expression

123
00:05:46.870 --> 00:05:49.702 align:middle line:90%
pattern matches.

124
00:05:49.702 --> 00:05:51.910 align:middle line:84%
Another condition, of course,
that we need to mention

125
00:05:51.910 --> 00:05:54.130 align:middle line:90%
is are there multiple cores?

126
00:05:54.130 --> 00:05:56.740 align:middle line:84%
If you have only a
single-core processor,

127
00:05:56.740 --> 00:05:59.080 align:middle line:90%
then things may work--

128
00:05:59.080 --> 00:06:02.920 align:middle line:84%
because obviously, multiple
threads can be multiplexed over

129
00:06:02.920 --> 00:06:05.710 align:middle line:84%
a single core by the underlying
operating system kernel

130
00:06:05.710 --> 00:06:09.190 align:middle line:84%
and operating system scheduler--
but you're very unlikely to see

131
00:06:09.190 --> 00:06:11.110 align:middle line:84%
much of a win in
terms of performance,

132
00:06:11.110 --> 00:06:15.070 align:middle line:84%
unless you have
highly I/O-bound jobs.

133
00:06:15.070 --> 00:06:16.870 align:middle line:84%
The good news is
pretty much everything

134
00:06:16.870 --> 00:06:19.360 align:middle line:84%
these days is going
to be multicore,

135
00:06:19.360 --> 00:06:22.870 align:middle line:84%
so it's pretty hard to buy
a single-core computer.

136
00:06:22.870 --> 00:06:27.730 align:middle line:84%
So the good news here is that
by leveraging today's commodity

137
00:06:27.730 --> 00:06:31.750 align:middle line:84%
quad-core, octa-core, and
so on computing platforms,

138
00:06:31.750 --> 00:06:35.050 align:middle line:84%
you're probably going to get
a relatively good speed up as

139
00:06:35.050 --> 00:06:38.320 align:middle line:84%
long as all these different
conditions are met.

140
00:06:38.320 --> 00:06:41.590 align:middle line:84%
Under the right conditions, we
saw that Java parallel streams

141
00:06:41.590 --> 00:06:45.790 align:middle line:84%
scale up very well on
multicore processors,

142
00:06:45.790 --> 00:06:48.220 align:middle line:84%
and you can see here
that, certainly compared

143
00:06:48.220 --> 00:06:51.550 align:middle line:84%
to the sequential stream version
or even the sequential loops

144
00:06:51.550 --> 00:06:55.013 align:middle line:84%
version that we also looked
at, the parallel streams

145
00:06:55.013 --> 00:06:56.680 align:middle line:84%
and parallel spliterator
implementations

146
00:06:56.680 --> 00:07:00.090 align:middle line:84%
are substantially,
substantially faster.