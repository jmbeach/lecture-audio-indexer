WEBVTT

1
00:00:00.000 --> 00:00:00.570 align:middle line:90%


2
00:00:00.570 --> 00:00:02.100 align:middle line:84%
The next several
lessons are going

3
00:00:02.100 --> 00:00:05.070 align:middle line:84%
to round out our discussion
of Java parallel streams

4
00:00:05.070 --> 00:00:09.330 align:middle line:84%
internals, starting by
focusing on non-concurrent and

5
00:00:09.330 --> 00:00:11.460 align:middle line:90%
concurrent collectors.

6
00:00:11.460 --> 00:00:13.590 align:middle line:84%
Naturally, this is still
part of the combined

7
00:00:13.590 --> 00:00:19.220 align:middle line:84%
phase of the Java parallel
streams phase pipeline.

8
00:00:19.220 --> 00:00:20.630 align:middle line:84%
In this part of
the lesson, we'll

9
00:00:20.630 --> 00:00:24.050 align:middle line:84%
recognize key behaviors
and differences

10
00:00:24.050 --> 00:00:28.770 align:middle line:84%
between non-concurrent
and concurrent collectors.

11
00:00:28.770 --> 00:00:32.070 align:middle line:84%
If you recall our discussions
from previous weeks,

12
00:00:32.070 --> 00:00:35.940 align:middle line:84%
collector is an interface
whose implementations

13
00:00:35.940 --> 00:00:39.220 align:middle line:84%
can accumulate input elements
into a mutable result

14
00:00:39.220 --> 00:00:41.730 align:middle line:90%
container.

15
00:00:41.730 --> 00:00:43.830 align:middle line:84%
Collector implementations
can either

16
00:00:43.830 --> 00:00:47.490 align:middle line:84%
be defined as concurrent
or as non-concurrent

17
00:00:47.490 --> 00:00:50.140 align:middle line:90%
based on their characteristics.

18
00:00:50.140 --> 00:00:52.050 align:middle line:84%
These are characteristics
that are returned

19
00:00:52.050 --> 00:00:54.930 align:middle line:84%
from the characteristics
factory method

20
00:00:54.930 --> 00:00:59.010 align:middle line:84%
and basically represent
metadata about the collector.

21
00:00:59.010 --> 00:01:03.750 align:middle line:84%
For example, is it ordered, is
it unordered, is it concurrent,

22
00:01:03.750 --> 00:01:05.980 align:middle line:84%
is it non-concurrent, does
it have identity finish,

23
00:01:05.980 --> 00:01:06.785 align:middle line:90%
and so on.

24
00:01:06.785 --> 00:01:08.160 align:middle line:84%
And these are the
different flags

25
00:01:08.160 --> 00:01:11.830 align:middle line:84%
that can be set to control the
semantics of the collector.

26
00:01:11.830 --> 00:01:14.440 align:middle line:84%
The distinction between
concurrent and non-concurrent

27
00:01:14.440 --> 00:01:18.770 align:middle line:84%
collectors are really only
relevant for parallel streams.

28
00:01:18.770 --> 00:01:21.230 align:middle line:84%
With a sequential stream,
of course, it doesn't really

29
00:01:21.230 --> 00:01:22.940 align:middle line:84%
matter because there's
only one thread,

30
00:01:22.940 --> 00:01:25.940 align:middle line:84%
so whether something is going to
be concurrent or non-concurrent

31
00:01:25.940 --> 00:01:28.280 align:middle line:84%
is really sort of a
no-op, but of course, you

32
00:01:28.280 --> 00:01:30.707 align:middle line:84%
should stick with using non
concurrent collectors for four

33
00:01:30.707 --> 00:01:32.540 align:middle line:84%
sequential streams,
because otherwise you're

34
00:01:32.540 --> 00:01:36.310 align:middle line:90%
adding unnecessary overhead.

35
00:01:36.310 --> 00:01:38.520 align:middle line:84%
For parallel streams,
however, things are different,

36
00:01:38.520 --> 00:01:40.270 align:middle line:84%
and we're going to be
focusing exclusively

37
00:01:40.270 --> 00:01:43.350 align:middle line:84%
on parallel streams
in this lesson.

38
00:01:43.350 --> 00:01:47.190 align:middle line:84%
For parallel streams, a
non-concurrent collector

39
00:01:47.190 --> 00:01:49.560 align:middle line:84%
allows you to work with
the parallel stream

40
00:01:49.560 --> 00:01:54.108 align:middle line:84%
in a different way than
a concurrent collector.

41
00:01:54.108 --> 00:01:55.650 align:middle line:84%
Of course, a
non-concurrent collector

42
00:01:55.650 --> 00:01:57.870 align:middle line:84%
can be used for either
a sequential stream

43
00:01:57.870 --> 00:01:59.080 align:middle line:90%
or a parallel stream.

44
00:01:59.080 --> 00:02:01.920 align:middle line:84%
So it's much like the
shimmer non-dairy floor

45
00:02:01.920 --> 00:02:06.120 align:middle line:84%
wax that's either a dessert
topping or a floor wax.

46
00:02:06.120 --> 00:02:07.920 align:middle line:84%
Let's start by
giving an overview

47
00:02:07.920 --> 00:02:10.110 align:middle line:84%
of the structure
and functionality

48
00:02:10.110 --> 00:02:12.660 align:middle line:90%
of non-concurrent collectors.

49
00:02:12.660 --> 00:02:16.980 align:middle line:84%
A non-concurrent collector
operates by merging sub-results

50
00:02:16.980 --> 00:02:18.710 align:middle line:90%
together.

51
00:02:18.710 --> 00:02:21.310 align:middle line:84%
Let's kind of review the
phases involved here.

52
00:02:21.310 --> 00:02:24.790 align:middle line:84%
In the split phase, the input
is partitioned into chunks

53
00:02:24.790 --> 00:02:28.540 align:middle line:84%
using parallel spliterators,
same as always.

54
00:02:28.540 --> 00:02:31.300 align:middle line:84%
In the apply phase,
each of these chunks

55
00:02:31.300 --> 00:02:34.510 align:middle line:84%
can run in parallel in
the common ForkJoinPool.

56
00:02:34.510 --> 00:02:38.940 align:middle line:84%
Again, nothing different
from what we've done before.

57
00:02:38.940 --> 00:02:40.470 align:middle line:84%
With the combined
phase, however,

58
00:02:40.470 --> 00:02:44.400 align:middle line:84%
for a non-concurrent
collector, the sub-results

59
00:02:44.400 --> 00:02:47.850 align:middle line:84%
that are emanating from
the common ForkJoinPool

60
00:02:47.850 --> 00:02:50.790 align:middle line:84%
when they process the chunks
are collected together

61
00:02:50.790 --> 00:02:55.050 align:middle line:84%
into an intermediate, mutable
result container, which

62
00:02:55.050 --> 00:02:57.810 align:middle line:84%
could typically be something
like a link list or an array

63
00:02:57.810 --> 00:03:01.780 align:middle line:84%
list or a hash setter or tree
set or a hash map and so on.

64
00:03:01.780 --> 00:03:04.080 align:middle line:84%
And so these different
mutable result containers

65
00:03:04.080 --> 00:03:08.400 align:middle line:84%
are each going to reside
in a different thread,

66
00:03:08.400 --> 00:03:10.840 align:middle line:84%
one thread for everything
that's running,

67
00:03:10.840 --> 00:03:14.940 align:middle line:84%
and one of the ForkJoin worker
threads in the ForkJoin worker

68
00:03:14.940 --> 00:03:16.410 align:middle line:90%
thread pool.

69
00:03:16.410 --> 00:03:17.880 align:middle line:84%
And each of these
different threads

70
00:03:17.880 --> 00:03:19.980 align:middle line:84%
will always operate
on different instances

71
00:03:19.980 --> 00:03:23.910 align:middle line:84%
of intermediate
result containers.

72
00:03:23.910 --> 00:03:27.510 align:middle line:84%
The sub-results are
merged successively,

73
00:03:27.510 --> 00:03:30.540 align:middle line:84%
as we kind of pull ourselves
out of the recursion,

74
00:03:30.540 --> 00:03:35.550 align:middle line:84%
if you will, into a single,
final reduced result container,

75
00:03:35.550 --> 00:03:38.640 align:middle line:84%
which is the result
of the whole reduction

76
00:03:38.640 --> 00:03:41.450 align:middle line:90%
of the parallel stream.

77
00:03:41.450 --> 00:03:43.910 align:middle line:84%
Only one thread in
the ForkJoinPool

78
00:03:43.910 --> 00:03:47.060 align:middle line:84%
is used to merge
together any pair

79
00:03:47.060 --> 00:03:50.480 align:middle line:84%
of intermediate sub-results
from an intermediate result

80
00:03:50.480 --> 00:03:51.680 align:middle line:90%
container.

81
00:03:51.680 --> 00:03:53.120 align:middle line:84%
And so as a
consequence, you never

82
00:03:53.120 --> 00:03:57.830 align:middle line:84%
have to worry about
putting locks in the code

83
00:03:57.830 --> 00:03:59.840 align:middle line:84%
here for non-concurrent
collectors,

84
00:03:59.840 --> 00:04:03.570 align:middle line:84%
because the merging is only ever
done in one thread at a time.

85
00:04:03.570 --> 00:04:05.490 align:middle line:84%
So there's no need for
any synchronization,

86
00:04:05.490 --> 00:04:08.240 align:middle line:84%
which simplifies your
life considerably.

87
00:04:08.240 --> 00:04:11.180 align:middle line:84%
Also, it allows you to use
very basic collections,

88
00:04:11.180 --> 00:04:15.840 align:middle line:84%
like array lists, which don't
have synchronized operations.

89
00:04:15.840 --> 00:04:19.320 align:middle line:84%
So to kind of take a step back
and evaluate the pros and cons

90
00:04:19.320 --> 00:04:23.550 align:middle line:84%
of this, using non-concurrent
collectors for parallel streams

91
00:04:23.550 --> 00:04:25.140 align:middle line:90%
is thread safe.

92
00:04:25.140 --> 00:04:27.330 align:middle line:90%
It's also order preserving.

93
00:04:27.330 --> 00:04:31.230 align:middle line:84%
It preserves in counter
order, but for certain types

94
00:04:31.230 --> 00:04:34.860 align:middle line:84%
of containers,
like maps and sets,

95
00:04:34.860 --> 00:04:38.130 align:middle line:84%
it can be costly, because
it is fairly expensive

96
00:04:38.130 --> 00:04:41.940 align:middle line:84%
to merge sets or merge maps
together multiple times

97
00:04:41.940 --> 00:04:47.130 align:middle line:84%
as we're moving up to the final
reduction in the final merge.

98
00:04:47.130 --> 00:04:49.560 align:middle line:84%
In contrast, if
you're going to merge

99
00:04:49.560 --> 00:04:51.150 align:middle line:84%
an array list, or a
linked list, those

100
00:04:51.150 --> 00:04:52.960 align:middle line:90%
are very simple operations.

101
00:04:52.960 --> 00:04:58.090 align:middle line:84%
But merging maps and sets
takes longer amounts of time.

102
00:04:58.090 --> 00:05:01.720 align:middle line:84%
To address those limitations
with non-concurrent collectors,

103
00:05:01.720 --> 00:05:04.150 align:middle line:84%
there's also the concept
of concurrent collectors

104
00:05:04.150 --> 00:05:05.835 align:middle line:90%
in Java parallel streams.

105
00:05:05.835 --> 00:05:07.960 align:middle line:84%
So what we're going to do
now is turn our attention

106
00:05:07.960 --> 00:05:12.720 align:middle line:84%
to analyzing their
structure and functionality.

107
00:05:12.720 --> 00:05:16.420 align:middle line:84%
A concurrent collector creates
one concurrent mutable result

108
00:05:16.420 --> 00:05:20.190 align:middle line:84%
container and then
accumulates elements into it

109
00:05:20.190 --> 00:05:23.083 align:middle line:84%
from multiple threads
in a parallel stream,

110
00:05:23.083 --> 00:05:24.750 align:middle line:84%
so there's only one
of these containers,

111
00:05:24.750 --> 00:05:26.190 align:middle line:90%
and it needs to be thread-safe.

112
00:05:26.190 --> 00:05:28.110 align:middle line:90%
It needs to be a concurrent--

113
00:05:28.110 --> 00:05:29.710 align:middle line:84%
a concurrent
collection actually.

114
00:05:29.710 --> 00:05:31.965 align:middle line:90%
It's a very common thing to use.

115
00:05:31.965 --> 00:05:33.590 align:middle line:84%
Let's walk through
the steps again just

116
00:05:33.590 --> 00:05:35.450 align:middle line:84%
to show how it
compares and contrasts

117
00:05:35.450 --> 00:05:38.960 align:middle line:84%
with the use of
non-concurrent collectors.

118
00:05:38.960 --> 00:05:40.640 align:middle line:84%
So as usual in the
splitting phase,

119
00:05:40.640 --> 00:05:42.350 align:middle line:84%
the input is
partitioned into chunks

120
00:05:42.350 --> 00:05:44.450 align:middle line:90%
using parallel spliterators.

121
00:05:44.450 --> 00:05:46.940 align:middle line:84%
In the apply phase, each
chunk runs in parallel

122
00:05:46.940 --> 00:05:48.680 align:middle line:90%
on the common ForkJoinPool.

123
00:05:48.680 --> 00:05:50.840 align:middle line:84%
Both those phases are
identical for concurrent and

124
00:05:50.840 --> 00:05:52.850 align:middle line:90%
non-concurrent collectors.

125
00:05:52.850 --> 00:05:55.820 align:middle line:84%
Where things get interesting
is in the combine phase.

126
00:05:55.820 --> 00:05:58.820 align:middle line:84%
In this model, the
sub-results from the chunks

127
00:05:58.820 --> 00:06:00.830 align:middle line:84%
that are processed
in the ForkJoinPool

128
00:06:00.830 --> 00:06:04.663 align:middle line:84%
are collected into a single
mutable result container,

129
00:06:04.663 --> 00:06:06.080 align:middle line:84%
typically a
concurrent collection,

130
00:06:06.080 --> 00:06:09.710 align:middle line:84%
like a concurrent hash map or
perhaps a concurrent hash set,

131
00:06:09.710 --> 00:06:12.600 align:middle line:84%
which we'll talk
about here shortly.

132
00:06:12.600 --> 00:06:14.760 align:middle line:84%
Different threads in
the parallel stream,

133
00:06:14.760 --> 00:06:17.610 align:middle line:84%
actually more specifically
in the common ForkJoinPool

134
00:06:17.610 --> 00:06:21.460 align:middle line:84%
share this one concurrent
result container.

135
00:06:21.460 --> 00:06:25.120 align:middle line:84%
And as a consequence,
there's no need

136
00:06:25.120 --> 00:06:29.270 align:middle line:84%
to merge any
intermediate sub-results.

137
00:06:29.270 --> 00:06:31.367 align:middle line:90%
However, this comes at a price.

138
00:06:31.367 --> 00:06:33.700 align:middle line:84%
One thing that happens is an
encounter order, of course,

139
00:06:33.700 --> 00:06:36.490 align:middle line:84%
is not preserved, because
we're just merging everything

140
00:06:36.490 --> 00:06:41.290 align:middle line:84%
into one container, so the
encounter order is ignored.

141
00:06:41.290 --> 00:06:44.422 align:middle line:84%
And synchronization
will be required.

142
00:06:44.422 --> 00:06:45.880 align:middle line:84%
Now, that's usually
not a big deal,

143
00:06:45.880 --> 00:06:47.338 align:middle line:84%
because you'll
typically simply use

144
00:06:47.338 --> 00:06:50.657 align:middle line:84%
a concurrent collection, like a
concurrent hash map and so on.

145
00:06:50.657 --> 00:06:52.490 align:middle line:84%
But it is something you
have to be aware of.

146
00:06:52.490 --> 00:06:56.680 align:middle line:84%
If you try to use something
very simple, like an array list,

147
00:06:56.680 --> 00:06:59.350 align:middle line:84%
for a concurrent collector,
chaos and insanity

148
00:06:59.350 --> 00:07:02.090 align:middle line:84%
will break out because array
list is not thread safe,

149
00:07:02.090 --> 00:07:05.200 align:middle line:84%
and so you'll end up with erase
conditions and corrupted values

150
00:07:05.200 --> 00:07:08.500 align:middle line:90%
in your list.

151
00:07:08.500 --> 00:07:10.800 align:middle line:84%
So when is a concurrent
collector a win?

152
00:07:10.800 --> 00:07:13.290 align:middle line:84%
A concurrent collector
could be a win

153
00:07:13.290 --> 00:07:18.060 align:middle line:84%
if the synchronization costs
for the concurrent collector

154
00:07:18.060 --> 00:07:23.190 align:middle line:84%
are lower than the merging costs
for a non-concurrent collector.

155
00:07:23.190 --> 00:07:25.260 align:middle line:84%
So put another way, the
concurrent collector

156
00:07:25.260 --> 00:07:27.810 align:middle line:84%
may outperform the
non-concurrent collector

157
00:07:27.810 --> 00:07:32.160 align:middle line:84%
if the merging costs are
higher for the non-concurrent

158
00:07:32.160 --> 00:07:34.380 align:middle line:84%
collector than the
synchronization costs are

159
00:07:34.380 --> 00:07:37.510 align:middle line:90%
for the concurrent collector.

160
00:07:37.510 --> 00:07:39.280 align:middle line:84%
Now, we're actually
going to take a look

161
00:07:39.280 --> 00:07:43.432 align:middle line:84%
and see how this all
plays out here later.

162
00:07:43.432 --> 00:07:45.640 align:middle line:84%
But for right now, let's
kind of compare and contrast

163
00:07:45.640 --> 00:07:49.330 align:middle line:84%
a couple of concrete examples
of result containers, which

164
00:07:49.330 --> 00:07:51.730 align:middle line:84%
are basically different
Java collections.

165
00:07:51.730 --> 00:07:54.550 align:middle line:84%
So it turns out that highly
optimized result containers,

166
00:07:54.550 --> 00:07:57.430 align:middle line:84%
like the concurrent
hash map collection,

167
00:07:57.430 --> 00:07:59.920 align:middle line:84%
may actually be more
efficient than trying

168
00:07:59.920 --> 00:08:04.103 align:middle line:84%
to merge non-synchronized
containers, like hash maps.

169
00:08:04.103 --> 00:08:05.520 align:middle line:84%
The reason for
that, of course, is

170
00:08:05.520 --> 00:08:09.350 align:middle line:84%
the concurrent hash map
is very cleverly designed

171
00:08:09.350 --> 00:08:12.140 align:middle line:84%
to have multiple
segment locks that

172
00:08:12.140 --> 00:08:15.150 align:middle line:84%
protect different groups of
buckets in the hash table,

173
00:08:15.150 --> 00:08:18.440 align:middle line:84%
and as long as values
that are being added to

174
00:08:18.440 --> 00:08:21.950 align:middle line:84%
or read from the
concurrent hash map

175
00:08:21.950 --> 00:08:24.650 align:middle line:84%
end up hashing to different
buckets that are controlled

176
00:08:24.650 --> 00:08:27.230 align:middle line:84%
or protected by
different segment locks,

177
00:08:27.230 --> 00:08:29.450 align:middle line:84%
there will be no
contention, and there'll

178
00:08:29.450 --> 00:08:32.549 align:middle line:84%
be no single point of overhead
in the concurrent hash map,

179
00:08:32.549 --> 00:08:35.580 align:middle line:84%
so that it's very
efficient in many cases.

180
00:08:35.580 --> 00:08:38.340 align:middle line:84%
Conversely, merging
two hash maps together

181
00:08:38.340 --> 00:08:40.970 align:middle line:90%
takes a fair amount of time.

182
00:08:40.970 --> 00:08:42.929 align:middle line:84%
It's also worth noting,
just as an aside,

183
00:08:42.929 --> 00:08:46.930 align:middle line:84%
that if you use a
concurrent collection for--

184
00:08:46.930 --> 00:08:49.150 align:middle line:84%
or if you use a
thread safe collection

185
00:08:49.150 --> 00:08:52.210 align:middle line:84%
for a concurrent collector, make
sure you stick with something

186
00:08:52.210 --> 00:08:54.820 align:middle line:84%
like concurrent hash
map, which is optimized

187
00:08:54.820 --> 00:08:58.720 align:middle line:84%
for concurrent access, rather
than use the more old school

188
00:08:58.720 --> 00:09:00.130 align:middle line:90%
synchronized map.

189
00:09:00.130 --> 00:09:01.840 align:middle line:84%
Synchronized map
was added as kind

190
00:09:01.840 --> 00:09:04.180 align:middle line:84%
of a stopgap in early
versions of Java

191
00:09:04.180 --> 00:09:07.030 align:middle line:84%
before they had the cool
concurrent hash map solution,

192
00:09:07.030 --> 00:09:09.910 align:middle line:84%
and it basically just
has a single synchronizer

193
00:09:09.910 --> 00:09:12.920 align:middle line:84%
that protects all the
various entries in the map.

194
00:09:12.920 --> 00:09:15.610 align:middle line:84%
So as a result when multiple
operations are trying

195
00:09:15.610 --> 00:09:18.860 align:middle line:84%
to get items into the
map, that single lock

196
00:09:18.860 --> 00:09:21.190 align:middle line:84%
will become a point
of contention,

197
00:09:21.190 --> 00:09:23.110 align:middle line:84%
whereas the
concurrent hash map is

198
00:09:23.110 --> 00:09:25.880 align:middle line:84%
unlikely to have those
single points of contention.

199
00:09:25.880 --> 00:09:27.400 align:middle line:84%
So probably much
better in practice

200
00:09:27.400 --> 00:09:30.900 align:middle line:84%
to use concurrent hash maps
for these kinds of uses.